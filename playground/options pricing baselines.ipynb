{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ca65a2b-98fc-4151-99f0-0ea1ea3992df",
   "metadata": {},
   "source": [
    "## 1. Overview\n",
    "### IVRMSE Baselines (BS/Black–76, Merton JD, Heston SV)\n",
    "\n",
    "**Purpose.** Build transparent, reproducible baselines for option pricing models and report **IVRMSE** (implied-vol RMSE) in publication-style tables.\n",
    "\n",
    "**Pipeline (per symbol):**  \n",
    "1) **Data prep (per day):** clean quotes, pair Calls & Puts, infer **forward $F$** and **discount $DF$** via put–call parity; compute **market Black–76 IV** per call.  \n",
    "2) **Calibration (per day × maturity bucket):**  \n",
    "   • **BS/Black–76:** fit a *single constant* $\\,\\sigma\\,$ in price space (cross-sectional SSE).  \n",
    "   • **Merton JD:** fit $(\\sigma,\\;\\lambda,\\;\\mu_J,\\;\\delta_J)$ by price SSE.  \n",
    "   • **Heston SV:** fit $(\\kappa,\\;\\theta,\\;\\sigma_v,\\;\\rho,\\;v_0)$ by price SSE (characteristic function + Simpson integration).  \n",
    "3) **Evaluation (per day × bucket):** price with the model, **invert to Black–76 IV**, and compute **IVRMSE** vs market IV, for slices **Whole / moneyness $<1$ / $>1$ / $>1.03$**.  \n",
    "4) **Aggregation (over period):**  \n",
    "   • **Primary** = equal-day mean IVRMSE (each day counts once)  \n",
    "   • **Secondary** = pooled (contract-weighted) IVRMSE  \n",
    "5) **Outputs:** daily table, equal-day mean, pooled, and a publication-style table (CSV + Markdown with bold minima).\n",
    "\n",
    "**Data schema expected:** `date, act_symbol|symbol, expiration, strike, call_put, bid, ask`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d173142-c962-44c6-9671-4b06e59f67d7",
   "metadata": {},
   "source": [
    "## 2. Black–76 helpers (pricing & IV inversion)\n",
    "\n",
    "### Pricing (forward measure)\n",
    "With forward $F$, strike $K$, maturity $\\tau$, rate $r$, and volatility $\\sigma$:\n",
    "$$\n",
    "C_{\\text{B76}} \\;=\\; DF\\,\\big(F\\,\\Phi(d_1) - K\\,\\Phi(d_2)\\big), \\qquad\n",
    "d_1=\\frac{\\ln(F/K)+\\tfrac12\\sigma^2\\tau}{\\sigma\\sqrt{\\tau}},\\quad\n",
    "d_2=d_1-\\sigma\\sqrt{\\tau},\n",
    "$$\n",
    "where $DF=e^{-r\\tau}$ and $\\Phi(\\cdot)$ is the standard normal CDF.  \n",
    "When $F$ and $DF$ are inferred via put–call parity, Black–76 coincides numerically with Black–Scholes on the same inputs.  \n",
    "**Edge cases:** if $\\tau\\le 0$ or $\\sigma\\le 0$, use the discounted intrinsic value $DF\\cdot\\max(F-K,0)$.\n",
    "\n",
    "### IV inversion (market price → implied $\\sigma$)\n",
    "Given the **market call price** $C^{\\text{mkt}}$ (we use the mid $(\\text{bid}+\\text{ask})/2$), clamp to the intrinsic value:\n",
    "$$\n",
    "\\tilde C \\;=\\; \\max\\!\\big(C^{\\text{mkt}},\\; DF\\cdot\\max(F-K,0)\\big).\n",
    "$$\n",
    "Solve for $\\sigma$ in\n",
    "$$\n",
    "C_{\\text{B76}}(F,K,\\tau,r,\\sigma) \\;=\\; \\tilde C\n",
    "$$\n",
    "using **bisection with bracket expansion**:\n",
    "start with $[\\sigma_{\\min},\\sigma_{\\max}] = [10^{-4},\\,5]$, expand $\\sigma_{\\max}$ until a sign change is found (or a safety cap), and stop when $|C_{\\text{B76}}-\\tilde C|$ is below tolerance or the interval is sufficiently small.  \n",
    "The solution is the market implied volatility $\\sigma_{\\text{mkt}}$ used downstream for IVRMSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5655d91-e334-48e0-9e9a-7891c4aaa04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "# Try SciPy for calibration; fall back to coarse grid if missing\n",
    "try:\n",
    "    from scipy.optimize import minimize\n",
    "    _HAVE_SCIPY = True\n",
    "except Exception:\n",
    "    _HAVE_SCIPY = False\n",
    "\n",
    "# ----------------------------\n",
    "# Black–76 pricing & IV inversion\n",
    "# ----------------------------\n",
    "\n",
    "def _norm_cdf(x: float) -> float:\n",
    "    return 0.5 * (1.0 + math.erf(x / math.sqrt(2.0)))\n",
    "\n",
    "def b76_price_call(F: float, K: float, tau: float, r: float, sigma: float) -> float:\n",
    "    \"\"\"Black–76 call price (also BS if F, DF inferred via parity).\"\"\"\n",
    "    if tau <= 0 or K <= 0 or F <= 0:\n",
    "        DF = math.exp(-r * max(tau, 0.0))\n",
    "        return DF * max(F - K, 0.0)\n",
    "    if sigma <= 0:\n",
    "        DF = math.exp(-r * tau)\n",
    "        return DF * max(F - K, 0.0)\n",
    "    v = sigma * math.sqrt(tau)\n",
    "    d1 = (math.log(F / K) + 0.5 * sigma * sigma * tau) / v\n",
    "    d2 = d1 - v\n",
    "    DF = math.exp(-r * tau)\n",
    "    return DF * (F * _norm_cdf(d1) - K * _norm_cdf(d2))\n",
    "\n",
    "def b76_iv_from_price(target: float, F: float, K: float, tau: float, r: float,\n",
    "                      tol: float = 1e-8, max_iter: int = 100,\n",
    "                      lo: float = 1e-4, hi: float = 5.0) -> Optional[float]:\n",
    "    \"\"\"Robust bisection with bracket expansion; clamps target to intrinsic.\"\"\"\n",
    "    if not (F > 0 and K > 0 and tau >= 0 and math.isfinite(target)):\n",
    "        return None\n",
    "    DF = math.exp(-r * tau)\n",
    "    intrinsic = DF * max(F - K, 0.0)\n",
    "    t = max(target, intrinsic)\n",
    "\n",
    "    def f(sig: float) -> float:\n",
    "        return b76_price_call(F, K, tau, r, sig) - t\n",
    "\n",
    "    a, b = lo, hi\n",
    "    fa, fb = f(a), f(b)\n",
    "    k = 0\n",
    "    while fa * fb > 0 and k < 25:\n",
    "        b *= 1.5\n",
    "        fb = f(b)\n",
    "        k += 1\n",
    "        if b > 50:\n",
    "            break\n",
    "    if fa * fb > 0:\n",
    "        return None\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        c = 0.5 * (a + b)\n",
    "        fc = f(c)\n",
    "        if abs(fc) < tol or 0.5 * (b - a) < 1e-8:\n",
    "            return c\n",
    "        if fa * fc <= 0:\n",
    "            b, fb = c, fc\n",
    "        else:\n",
    "            a, fa = c, fc\n",
    "    return 0.5 * (a + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18f0f8a-77a5-47b0-8c6d-013178c55758",
   "metadata": {},
   "source": [
    "## 3. Put–call parity → infer forward $F$ and discount $DF$\n",
    "\n",
    "For all strikes on the same **(day, symbol, expiry)**, with midprices $C$ (call) and $P$ (put):\n",
    "$$\n",
    "C - P \\;=\\; DF\\,(F - K) \\;=\\; a \\;+\\; b(-K).\n",
    "$$\n",
    "\n",
    "**OLS regression across strikes.**  \n",
    "Let $y_i = C_i - P_i$ and $x_i = -K_i$. Fit the line\n",
    "$$\n",
    "y_i \\;=\\; a \\;+\\; b\\,x_i\n",
    "$$\n",
    "by least squares using all **paired** call–put quotes for that expiry.\n",
    "\n",
    "**Recover forward and discount:**\n",
    "- **Discount factor:** $DF = b$  \n",
    "- **Forward:** $F = \\dfrac{a}{DF}$  \n",
    "- **Short rate:** $r = -\\dfrac{\\ln(DF)}{\\tau}$ (with $\\tau$ in years)\n",
    "\n",
    "**Practical notes.**\n",
    "- Require at least **two** call–put pairs for the regression.  \n",
    "- Drop the expiry if the fit gives nonpositive $DF$ or nonpositive $F$.  \n",
    "- With only **one** pair available, a safe fallback is $DF=1$ and $F=C-P+K$ (used only when necessary).\n",
    "\n",
    "This parity step produces $(F, DF, r)$ per expiry, which we then use for pricing and IV inversion downstream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bac9c64c-a150-40db-b7bb-a7b643876fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Put–call parity: infer F and DF\n",
    "# ----------------------------\n",
    "\n",
    "def parity_infer_F_DF(df_pairs: pd.DataFrame) -> Optional[Tuple[float, float]]:\n",
    "    \"\"\"\n",
    "    Infer forward F and discount DF from (C - P) vs K.\n",
    "    y = C - P = DF*(F - K) = a + b*(-K)  ->  b = DF,  F = a/DF.\n",
    "    \"\"\"\n",
    "    y = (df_pairs[\"C_mid\"].values - df_pairs[\"P_mid\"].values).astype(float)\n",
    "    X = df_pairs[\"strike\"].values.astype(float)\n",
    "    if len(y) < 2:\n",
    "        # fallback with single pair\n",
    "        K0 = float(df_pairs[\"strike\"].iloc[0])\n",
    "        DF = 1.0\n",
    "        F = float(y[0] + K0)\n",
    "        return F, DF\n",
    "    Xmat = np.column_stack([np.ones_like(X), -X])\n",
    "    a, b = np.linalg.lstsq(Xmat, y, rcond=None)[0]\n",
    "    DF = float(b)\n",
    "    if not np.isfinite(DF) or DF <= 0:\n",
    "        return None\n",
    "    F = float(a / DF)\n",
    "    if not np.isfinite(F) or F <= 0:\n",
    "        return None\n",
    "    return F, DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c941770a-cfdd-4c38-aeb6-0652e4260569",
   "metadata": {},
   "source": [
    "## 4. Maturity bucketing & one-parameter BS fit\n",
    "\n",
    "**Bucketing by maturity.**  \n",
    "Map time-to-expiry $\\tau$ (in years) to the nearest center in **calendar days** (e.g., 14d / 28d / 56d).  \n",
    "This groups strikes for a given **(day, symbol)** into cross-sections with similar maturities.\n",
    "\n",
    "**Single-parameter BS baseline (per bucket).**  \n",
    "Fit a **constant volatility** $\\hat{\\sigma}$ by minimizing **call price SSE** over all strikes in the bucket:\n",
    "$$\n",
    "\\hat{\\sigma}\n",
    "\\;=\\;\n",
    "\\arg\\min_{\\sigma>0}\\;\n",
    "\\sum_{i\\in \\text{bucket}}\n",
    "\\Big(\n",
    "C_{\\text{B76}}(F_i,K_i,\\tau_i,r_i,\\sigma)\\;-\\;C^{\\text{mkt}}_i\n",
    "\\Big)^2.\n",
    "$$\n",
    "\n",
    "**Numerics.**  \n",
    "- Start with a **log-spaced grid** for $\\sigma$ (e.g., $[0.05,\\,2.0]$); pick the best grid point.  \n",
    "- **Refine** via **golden-section search** on a bracket around the best grid value.  \n",
    "- Edge cases: if a candidate $\\sigma\\le 0$, fall back to discounted intrinsic $DF\\cdot\\max(F-K,0)$ inside pricing.\n",
    "\n",
    "**Evaluation → IVRMSE slices.**  \n",
    "Treat the fitted $\\hat{\\sigma}$ as the model’s **implied vol** and compare to **market B76 IVs** within the bucket:\n",
    "- **Whole**: all strikes,  \n",
    "- **$m<1$**: $m=K/F<1$ (OTM calls / ITM puts),  \n",
    "- **$m>1$**: $K/F>1$,  \n",
    "- **$m>1.03$**: deeper OTM calls.\n",
    "\n",
    "For a slice $\\mathcal{S}$, the reported metric is\n",
    "$$\n",
    "\\text{IVRMSE}_\\mathcal{S}\n",
    "\\;=\\;\n",
    "\\sqrt{\\;\\frac{1}{|\\mathcal{S}|}\\sum_{i\\in\\mathcal{S}}\n",
    "\\big(\\hat{\\sigma}\\;-\\;\\sigma^{\\text{mkt}}_i\\big)^2\\;}\\;\\times 1000,\n",
    "$$\n",
    "i.e., RMSE in **implied-vol space**, scaled by **1000** as in the reference tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff1af95c-4703-4a42-a649-2249978218df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Maturity bucketing & σ fit\n",
    "# ----------------------------\n",
    "\n",
    "def assign_bucket(tau_years: float, centers_days: List[int] = [14, 28, 56]) -> str:\n",
    "    \"\"\"Map τ (years) to nearest maturity center in days: '14d'/'28d'/'56d'.\"\"\"\n",
    "    days = tau_years * 365.0\n",
    "    idx = int(np.argmin([abs(days - c) for c in centers_days]))\n",
    "    return f\"{centers_days[idx]}d\"\n",
    "\n",
    "def fit_sigma_bucket(df_bucket: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    1-parameter BS/B76 baseline: choose σ minimizing price SSE.\n",
    "    Coarse grid (geomspace) + golden-section refinement.\n",
    "    \"\"\"\n",
    "    if len(df_bucket) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    def sse(sig: float) -> float:\n",
    "        if sig <= 0:\n",
    "            return 1e18\n",
    "        prices = df_bucket.apply(\n",
    "            lambda r: b76_price_call(r[\"F\"], r[\"strike\"], r[\"tau\"], r[\"r\"], sig), axis=1\n",
    "        ).values\n",
    "        err = prices - df_bucket[\"C_mid\"].values\n",
    "        return float(np.dot(err, err))\n",
    "\n",
    "    grid = np.geomspace(0.05, 2.0, 40)\n",
    "    best = min(grid, key=sse)\n",
    "    a = max(best / 3, 1e-4)\n",
    "    b = min(best * 3, 5.0)\n",
    "    phi = (1 + np.sqrt(5)) / 2\n",
    "    invphi = 1 / phi\n",
    "    c = b - (b - a) * invphi\n",
    "    d = a + (b - a) * invphi\n",
    "    fc, fd = sse(c), sse(d)\n",
    "    for _ in range(60):\n",
    "        if fc < fd:\n",
    "            b, d, fd = d, c, fc\n",
    "            c = b - (b - a) * invphi\n",
    "            fc = sse(c)\n",
    "        else:\n",
    "            a, c, fc = c, d, fd\n",
    "            d = a + (b - a) * invphi\n",
    "            fd = sse(d)\n",
    "    return float((a + b) / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff1c592-f0c1-4fd1-9d36-fb2b3e94fbfc",
   "metadata": {},
   "source": [
    "## 5. Merton Jump–Diffusion (JD)\n",
    "\n",
    "**Model.** Log-returns combine a continuous diffusion (volatility $\\sigma$) with **compound Poisson jumps** of intensity $\\lambda$ and jump sizes $Y\\sim\\mathcal{N}(\\mu_J,\\delta_J^2)$.  \n",
    "Under the risk-neutral forward measure (we work with forward $F$ and discount $DF=e^{-r\\tau}$), the call price is a **Poisson mixture** of Black–76 prices:\n",
    "\n",
    "$$\n",
    "C_{\\text{JD}} \\;=\\; \n",
    "\\sum_{n=0}^{\\infty} p_n \\;\n",
    "C_{\\text{B76}}\\!\\big(F_n,\\;K,\\;\\tau,\\;r,\\;\\sigma_n\\big),\n",
    "\\qquad \n",
    "p_n \\;=\\; e^{-\\lambda\\tau}\\frac{(\\lambda\\tau)^n}{n!}.\n",
    "$$\n",
    "\n",
    "**Compensation (drift fix) and mixture terms.**  \n",
    "Because jumps are modeled in log-price, we compensate the forward so the overall drift stays risk-neutral:\n",
    "$$\n",
    "k \\;=\\; \\mathbb{E}[e^{Y}] - 1 \\;=\\; e^{\\mu_J+\\tfrac12 \\delta_J^2} - 1, \n",
    "\\qquad\n",
    "F_{\\text{adj}} \\;=\\; F\\; e^{-\\lambda k \\tau}.\n",
    "$$\n",
    "For the $n$-jump component,\n",
    "$$\n",
    "F_n \\;=\\; F_{\\text{adj}} \\, e^{n\\mu_J}, \n",
    "\\qquad \n",
    "\\sigma_n^2 \\;=\\; \\sigma^2 \\;+\\; \\frac{n\\,\\delta_J^2}{\\tau}.\n",
    "$$\n",
    "\n",
    "**Calibration (per day × bucket).**  \n",
    "Estimate $\\theta=(\\sigma,\\lambda,\\mu_J,\\delta_J)$ by minimizing **call price SSE** on the bucket cross-section:\n",
    "$$\n",
    "\\min_{\\theta}\\; \n",
    "\\sum_{i\\in \\text{bucket}}\n",
    "\\Big(\n",
    "C_{\\text{JD}}(F_i,K_i,\\tau_i,r_i;\\theta) - C^{\\text{mkt}}_i\n",
    "\\Big)^2.\n",
    "$$\n",
    "\n",
    "**Numerics.**\n",
    "- **Poisson truncation:** sum terms until the cumulative mass exceeds $1-\\varepsilon$ (e.g., $\\varepsilon=10^{-8}$), or up to a cap $n_{\\max}$ (e.g., 50–80).  \n",
    "- **Initialization (robust):** $\\sigma \\approx \\text{median ATM IV}$, $\\lambda\\!\\approx\\!0.1$, $\\mu_J\\!\\approx\\!-0.02$, $\\delta_J\\!\\approx\\!0.10$.  \n",
    "- **Typical bounds:** $\\sigma\\in[0.01,3]$, $\\lambda\\in[0,5]$, $\\mu_J\\in[-0.5,0.5]$, $\\delta_J\\in[0.01,1]$.  \n",
    "- **Identifiability note:** for short maturities, $(\\sigma,\\delta_J,\\lambda)$ can trade off; use sensible bounds and regularization (if needed).\n",
    "\n",
    "**Evaluation for IVRMSE (downstream).**  \n",
    "After calibration, price each strike with $C_{\\text{JD}}$, **invert to B76 IV**, and compare to market IV to form IVRMSE slices (Whole, $m<1$, $m>1$, $m>1.03$), consistent with the BS baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64a6c370-ad8b-4135-920d-41d0dd02d68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Merton Jump–Diffusion (JD)\n",
    "# ============================================================\n",
    "\n",
    "def merton_price_call_b76(F: float, K: float, tau: float, r: float,\n",
    "                          sigma: float, lam: float, muJ: float, deltaJ: float,\n",
    "                          eps_tail: float = 1e-8, n_max: int = 80) -> float:\n",
    "    \"\"\"\n",
    "    Merton JD via Poisson mixture of B76 prices.\n",
    "    Compensation k = E[e^Y]-1 = exp(muJ + 0.5*deltaJ^2) - 1\n",
    "    Use F_adj = F * exp(-lam * k * tau).\n",
    "    For n jumps: F_n = F_adj * exp(n*muJ), sigma_n^2 = sigma^2 + n*deltaJ^2 / tau.\n",
    "    \"\"\"\n",
    "    if tau <= 0:\n",
    "        DF = math.exp(-r * max(tau, 0.0))\n",
    "        return DF * max(F - K, 0.0)\n",
    "\n",
    "    k = math.exp(muJ + 0.5 * deltaJ * deltaJ) - 1.0\n",
    "    F_adj = F * math.exp(-lam * k * tau)\n",
    "    L = lam * tau\n",
    "\n",
    "    p = math.exp(-L)  # p0\n",
    "    price = p * b76_price_call(F_adj, K, tau, r, sigma)\n",
    "    cum = p\n",
    "    n = 0\n",
    "    while cum < 1 - eps_tail and n < n_max:\n",
    "        n += 1\n",
    "        p = p * (L / n)  # p_n\n",
    "        sigma_n = math.sqrt(sigma * sigma + (n * deltaJ * deltaJ) / max(tau, 1e-12))\n",
    "        F_n = F_adj * math.exp(n * muJ)\n",
    "        price += p * b76_price_call(F_n, K, tau, r, sigma_n)\n",
    "        cum += p\n",
    "    return float(price)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c77844-0d06-49dd-bf2f-6f2ead4ba630",
   "metadata": {},
   "source": [
    "## 6. Heston Stochastic Volatility (SV) via characteristic function\n",
    "\n",
    "**Model (under risk-neutral dynamics).**  \n",
    "Stock variance follows\n",
    "$$\n",
    "dv_t \\;=\\; \\kappa(\\theta - v_t)\\,dt \\;+\\; \\sigma_v\\sqrt{v_t}\\,dW_t^{(2)},\n",
    "\\qquad\n",
    "dW_t^{(1)}\\,dW_t^{(2)} \\;=\\; \\rho\\,dt,\n",
    "$$\n",
    "and $dS_t = S_t\\sqrt{v_t}\\,dW_t^{(1)}$ after the drift is adjusted for risk neutrality.  \n",
    "We work under the **forward measure** using parity-inferred inputs: set $S_0 \\to F$ and $q=r$ so that pricing uses the forward $F$ and discount $DF=e^{-r\\tau}$.\n",
    "\n",
    "**Pricing via $P_1/P_2$ integrals.**  \n",
    "The Heston call price is\n",
    "$$\n",
    "C \\;=\\; DF\\,\\big(F\\,P_1 \\;-\\; K\\,P_2\\big),\n",
    "$$\n",
    "with\n",
    "$$\n",
    "P_2 \\;=\\; \\tfrac12 \\;+\\; \\tfrac{1}{\\pi}\\int_0^\\infty \n",
    "\\Re\\!\\left\\{ e^{-iu\\ln K}\\,\\frac{\\phi(u)}{iu} \\right\\}\\,du,\n",
    "\\qquad\n",
    "P_1 \\;=\\; \\tfrac12 \\;+\\; \\tfrac{1}{\\pi}\\int_0^\\infty \n",
    "\\Re\\!\\left\\{ e^{-iu\\ln K}\\,\\frac{\\phi(u-i)}{iu\\,\\phi(-i)} \\right\\}\\,du.\n",
    "$$\n",
    "\n",
    "**Characteristic function (little Heston trap).**  \n",
    "Let $x=\\ln F$, $i=\\sqrt{-1}$, and define\n",
    "$$\n",
    "d(u) \\;=\\; \\sqrt{(\\rho\\,\\sigma_v\\,iu - \\kappa)^2 + \\sigma_v^2\\,(iu + u^2)},\\qquad\n",
    "g(u) \\;=\\; \\frac{\\kappa - \\rho\\,\\sigma_v\\,iu - d(u)}{\\kappa - \\rho\\,\\sigma_v\\,iu + d(u)}.\n",
    "$$\n",
    "Then\n",
    "$$\n",
    "\\begin{aligned}\n",
    "C(u) &= \\frac{\\kappa\\theta}{\\sigma_v^2}\n",
    "\\Big[(\\kappa - \\rho\\,\\sigma_v\\,iu - d(u))\\,\\tau\n",
    "\\;-\\; 2\\ln\\!\\Big(\\frac{1 - g(u)\\,e^{-d(u)\\tau}}{1 - g(u)}\\Big)\\Big],\\\\[4pt]\n",
    "D(u) &= \\frac{\\kappa - \\rho\\,\\sigma_v\\,iu - d(u)}{\\sigma_v^2}\n",
    "\\cdot \\frac{1 - e^{-d(u)\\tau}}{1 - g(u)\\,e^{-d(u)\\tau}},\n",
    "\\end{aligned}\n",
    "$$\n",
    "and the **characteristic function** of $\\ln S_T$ (under the forward measure) is\n",
    "$$\n",
    "\\phi(u) \\;=\\; \\exp\\!\\big( C(u) + D(u)\\,v_0 + iu\\,x \\big).\n",
    "$$\n",
    "\n",
    "**Numerics.**  \n",
    "- Compute $P_1, P_2$ by **Simpson’s rule** on a uniform grid $u\\in(0,u_{\\max})$ (e.g., $u_{\\max}\\in[80,100]$, 400–600 points).  \n",
    "- Use the “little trap” form above to avoid branch-cut issues for the complex logarithm.  \n",
    "- Discount with $DF=e^{-r\\tau}$ where $r$ is inferred from parity via $DF$.\n",
    "\n",
    "**Calibration (per day × maturity bucket).**  \n",
    "Fit $\\Theta=(\\kappa,\\theta,\\sigma_v,\\rho,v_0)$ by minimizing **call price SSE** over the bucket cross-section:\n",
    "$$\n",
    "\\min_{\\Theta}\\; \\sum_{i\\in\\text{bucket}}\n",
    "\\Big(C_{\\text{Heston}}(F_i,K_i,\\tau_i,r_i;\\Theta) - C^{\\text{mkt}}_i\\Big)^2.\n",
    "$$\n",
    "Practical choices:\n",
    "- **Initialization:** $v_0 \\approx (\\text{ATM IV})^2$, $\\kappa\\approx 2$, $\\theta\\approx v_0$, $\\sigma_v\\approx 0.5$, $\\rho\\approx -0.5$.  \n",
    "- **Bounds:** $\\kappa>0$, $\\theta>0$, $\\sigma_v>0$, $\\rho\\in[-0.999,0]$, $v_0>0$.\n",
    "\n",
    "**Evaluation for IVRMSE.**  \n",
    "After calibration, price each strike with Heston, **invert the price to a Black–76 IV**, and compare to the market B76 IV to form IVRMSE slices (Whole, $m<1$, $m>1$, $m>1.03$), consistent with BS and JD baselines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a61d27b-2224-4ef8-92a8-62f3120c0af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Merton Jump–Diffusion (JD)\n",
    "# ============================================================\n",
    "\n",
    "def merton_price_call_b76(F: float, K: float, tau: float, r: float,\n",
    "                          sigma: float, lam: float, muJ: float, deltaJ: float,\n",
    "                          eps_tail: float = 1e-8, n_max: int = 80) -> float:\n",
    "    \"\"\"\n",
    "    Merton JD via Poisson mixture of B76 prices.\n",
    "    Compensation k = E[e^Y]-1 = exp(muJ + 0.5*deltaJ^2) - 1\n",
    "    Use F_adj = F * exp(-lam * k * tau).\n",
    "    For n jumps: F_n = F_adj * exp(n*muJ), sigma_n^2 = sigma^2 + n*deltaJ^2 / tau.\n",
    "    \"\"\"\n",
    "    if tau <= 0:\n",
    "        DF = math.exp(-r * max(tau, 0.0))\n",
    "        return DF * max(F - K, 0.0)\n",
    "\n",
    "    k = math.exp(muJ + 0.5 * deltaJ * deltaJ) - 1.0\n",
    "    F_adj = F * math.exp(-lam * k * tau)\n",
    "    L = lam * tau\n",
    "\n",
    "    p = math.exp(-L)  # p0\n",
    "    price = p * b76_price_call(F_adj, K, tau, r, sigma)\n",
    "    cum = p\n",
    "    n = 0\n",
    "    while cum < 1 - eps_tail and n < n_max:\n",
    "        n += 1\n",
    "        p = p * (L / n)  # p_n\n",
    "        sigma_n = math.sqrt(sigma * sigma + (n * deltaJ * deltaJ) / max(tau, 1e-12))\n",
    "        F_n = F_adj * math.exp(n * muJ)\n",
    "        price += p * b76_price_call(F_n, K, tau, r, sigma_n)\n",
    "        cum += p\n",
    "    return float(price)\n",
    "\n",
    "# ============================================================\n",
    "# Heston Stochastic Volatility (SV)\n",
    "# ============================================================\n",
    "\n",
    "def _heston_cf(u: np.ndarray, F: float, tau: float,\n",
    "               kappa: float, theta: float, sigma_v: float, rho: float, v0: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Heston characteristic function φ(u) for log-price under forward measure\n",
    "    (set S0 = F and q = r). Implements the \"little Heston trap\" form.\n",
    "    Vectorized over u (real or complex).\n",
    "    \"\"\"\n",
    "    x = math.log(F)\n",
    "    iu = 1j * u\n",
    "    d = np.sqrt((rho * sigma_v * iu - kappa)**2 + sigma_v**2 * (iu + u*u))\n",
    "    g = (kappa - rho * sigma_v * iu - d) / (kappa - rho * sigma_v * iu + d)\n",
    "    exp_dt = np.exp(-d * tau)\n",
    "    C = (kappa * theta / (sigma_v**2)) * ((kappa - rho * sigma_v * iu - d) * tau - 2.0 * np.log((1 - g * exp_dt) / (1 - g)))\n",
    "    D = ((kappa - rho * sigma_v * iu - d) / (sigma_v**2)) * ((1 - exp_dt) / (1 - g * exp_dt))\n",
    "    return np.exp(C + D * v0 + iu * x)\n",
    "\n",
    "def _simpson_integral(fx: np.ndarray, dx: float) -> float:\n",
    "    \"\"\"Simpson’s rule; falls back to trapz if <3 points. Ensures odd #points.\"\"\"\n",
    "    n = len(fx)\n",
    "    if n < 3:\n",
    "        return float(np.trapz(fx, dx=dx))\n",
    "    if n % 2 == 0:\n",
    "        fx = fx[:-1]; n -= 1\n",
    "    S = fx[0] + fx[-1] + 4.0 * fx[1:-1:2].sum() + 2.0 * fx[2:-2:2].sum()\n",
    "    return float((dx / 3.0) * S)\n",
    "\n",
    "def _heston_prob(F: float, K: float, tau: float, params: Dict[str, float],\n",
    "                 j: int, u_max: float = 100.0, n_points: int = 501) -> float:\n",
    "    \"\"\"\n",
    "    Risk-neutral probabilities P1 (j=1) and P2 (j=2):\n",
    "      P2 = 1/2 + 1/π ∫_0^∞ Re[ e^{-i u ln K} φ(u) / (i u) ] du\n",
    "      P1 = 1/2 + 1/π ∫_0^∞ Re[ e^{-i u ln K} φ(u - i) / (i u * φ(-i)) ] du\n",
    "    \"\"\"\n",
    "    kappa, theta, sigma_v, rho, v0 = params[\"kappa\"], params[\"theta\"], params[\"sigma_v\"], params[\"rho\"], params[\"v0\"]\n",
    "    lnK = math.log(K)\n",
    "    u = np.linspace(1e-6, u_max, n_points)\n",
    "    du = u[1] - u[0]\n",
    "\n",
    "    if j == 2:\n",
    "        phi = _heston_cf(u, F, tau, kappa, theta, sigma_v, rho, v0)\n",
    "        integrand = np.real(np.exp(-1j * u * lnK) * phi / (1j * u))\n",
    "    else:\n",
    "        phi_shift = _heston_cf(u - 1j, F, tau, kappa, theta, sigma_v, rho, v0)\n",
    "        phi_mi = _heston_cf(np.array([-1j]), F, tau, kappa, theta, sigma_v, rho, v0)[0]\n",
    "        integrand = np.real(np.exp(-1j * u * lnK) * (phi_shift / (1j * u * phi_mi)))\n",
    "\n",
    "    integral = _simpson_integral(integrand, du)\n",
    "    return float(0.5 + (1.0 / math.pi) * integral)\n",
    "\n",
    "def heston_price_call(F: float, K: float, tau: float, r: float, params: Dict[str, float],\n",
    "                      u_max: float = 100.0, n_points: int = 501) -> float:\n",
    "    \"\"\"Heston price via P1/P2 under forward measure.\"\"\"\n",
    "    DF = math.exp(-r * tau)\n",
    "    P1 = _heston_prob(F, K, tau, params, j=1, u_max=u_max, n_points=n_points)\n",
    "    P2 = _heston_prob(F, K, tau, params, j=2, u_max=u_max, n_points=n_points)\n",
    "    return DF * (F * P1 - K * P2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049f6a78-309f-4eea-a9c0-dc3d76f788d1",
   "metadata": {},
   "source": [
    "## 7. Data preparation → Calls with market Black–76 IVs\n",
    "\n",
    "**Goal.** From raw quotes on a given **(day, symbol)**, build a clean cross-section of calls with:\n",
    "forward $F$, discount $DF$, short rate $r$, year-fraction $\\tau$, bucket label, and **market B76 IV** per strike.\n",
    "\n",
    "### Inputs (expected columns)\n",
    "`date, act_symbol|symbol, expiration, strike, call_put, bid, ask`.\n",
    "\n",
    "### Step 1 — Basic cleaning\n",
    "- Parse `date` and `expiration`; compute **calendar-day** year fraction  \n",
    "  $$\\tau \\;=\\; \\frac{\\text{expiration} - \\text{date}}{365}.$$\n",
    "- Require valid quotes: `bid ≥ 0`, `ask ≥ bid`.  \n",
    "- Define midprice  \n",
    "  $$\\text{mid} \\;=\\; \\frac{\\text{bid} + \\text{ask}}{2} \\;>\\; 0.$$\n",
    "- Optional guardrails:\n",
    "  - drop rows with $\\tau \\le 0$,\n",
    "  - apply a **$\\tau$ floor** (e.g., $\\ge$ 3 days) to exclude micro-expiries.\n",
    "\n",
    "### Step 2 — Pair calls and puts by strike\n",
    "- Pivot by (`date`, `symbol`, `expiration`, `tau`, `strike`) to obtain both **Call** and **Put** mids on the same grid.  \n",
    "- Keep only **pairs** (both sides present) — these are used for parity.\n",
    "\n",
    "### Step 3 — Put–call parity per expiry → $(F, DF, r)$\n",
    "- For each expiry on that day, regress across strikes:\n",
    "  $$\n",
    "  C - P \\;=\\; DF\\,(F - K) \\;=\\; a + b(-K).\n",
    "  $$\n",
    "  Then **slope** $b=DF$, **intercept** $a=DF\\cdot F \\Rightarrow F=a/DF$.\n",
    "- Recover the short rate from the discount factor:\n",
    "  $$ r \\;=\\; -\\frac{\\ln(DF)}{\\tau}. $$\n",
    "- Require at least **two** call–put pairs; discard if $DF \\le 0$ or $F \\le 0$.  \n",
    "  *(Fallback when only one pair exists: set $DF=1$, $F=C-P+K$ — used sparingly.)*\n",
    "\n",
    "### Step 4 — Market B76 IVs (calls only)\n",
    "- For each **call** row at that expiry, invert the Black–76 price to get\n",
    "  $$\\sigma_i^{\\text{mkt}} \\quad \\text{such that}\\quad\n",
    "    C_{\\text{B76}}(F_i,K_i,\\tau_i,r_i,\\sigma_i^{\\text{mkt}}) \\;=\\; \\max\\!\\big(\\text{mid}_i,\\; DF_i\\max(F_i-K_i,0)\\big).$$\n",
    "  (Clamp to intrinsic ensures feasibility; solve via bisection with bracket expansion.)\n",
    "\n",
    "### Step 5 — Moneyness & maturity buckets\n",
    "- Define moneyness  \n",
    "  $$ m \\;=\\; \\frac{K}{F}. $$\n",
    "- Map $\\tau$ to the nearest **bucket center** in calendar days (e.g., **14d**, **28d**, **56d**).  \n",
    "  These buckets are used for **same-maturity** cross-sectional calibration.\n",
    "\n",
    "### Output of this stage\n",
    "A per-day DataFrame of calls with columns like:  \n",
    "`date, symbol, expiration, tau, strike, C_mid, F, DF, r, sigma_mkt_b76, moneyness_F, bucket`  \n",
    "This is the input for calibration and IVRMSE evaluation in later sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76c88269-6059-4b28-bbef-756642df36bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Data prep: one day & symbol -> calls with market IVs\n",
    "# ============================================================\n",
    "\n",
    "def prepare_calls_one_day_symbol(df_day_symbol: pd.DataFrame,\n",
    "                                 min_parity_pairs: int = 2,\n",
    "                                 tau_floor_days: int = 0) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Input (one trading day × one symbol quotes) →\n",
    "      calls_df with: F, DF, r, tau, bucket, market B76 IV (calls only)\n",
    "      parity_df with per-expiry inferred (F, DF, r).\n",
    "    \"\"\"\n",
    "    df = df_day_symbol.copy()\n",
    "    # normalize schema (accept 'act_symbol' or 'symbol')\n",
    "    rename_map = {\"date\":\"date\",\"expiration\":\"expiration\",\"strike\":\"strike\",\"call_put\":\"cp\",\"bid\":\"bid\",\"ask\":\"ask\"}\n",
    "    if \"act_symbol\" in df.columns: rename_map[\"act_symbol\"] = \"symbol\"\n",
    "    elif \"symbol\" in df.columns:   rename_map[\"symbol\"] = \"symbol\"\n",
    "    else: raise ValueError(\"Expected 'act_symbol' or 'symbol' column.\")\n",
    "    df = df.rename(columns=rename_map)\n",
    "\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df[\"expiration\"] = pd.to_datetime(df[\"expiration\"])\n",
    "    df[\"tau\"] = (df[\"expiration\"] - df[\"date\"]).dt.days / 365.0\n",
    "\n",
    "    df[\"bid\"] = pd.to_numeric(df[\"bid\"], errors=\"coerce\")\n",
    "    df[\"ask\"] = pd.to_numeric(df[\"ask\"], errors=\"coerce\")\n",
    "    df[\"mid\"] = (df[\"bid\"].clip(lower=0) + df[\"ask\"].clip(lower=0)) / 2.0\n",
    "\n",
    "    # cleaning & optional τ floor\n",
    "    df = df[df[\"mid\"].notna() & (df[\"mid\"] > 0) & (df[\"ask\"] >= df[\"bid\"]) & (df[\"bid\"] >= 0) & (df[\"tau\"] > 0)]\n",
    "    if tau_floor_days and tau_floor_days > 0:\n",
    "        df = df[df[\"tau\"] * 365.0 >= tau_floor_days]\n",
    "    if df.empty: return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    # pair calls & puts\n",
    "    pvt = df.pivot_table(index=[\"date\",\"symbol\",\"expiration\",\"tau\",\"strike\"],\n",
    "                         columns=\"cp\", values=\"mid\", aggfunc=\"first\").reset_index()\n",
    "    pvt = pvt.rename(columns={\"Call\":\"C_mid\",\"Put\":\"P_mid\"})\n",
    "    pairs = pvt.dropna(subset=[\"C_mid\",\"P_mid\"])\n",
    "    if pairs.empty:\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    # infer F, DF, r per expiry\n",
    "    recs, parity_rows = [], []\n",
    "    for (date, sym, exp), g in pairs.groupby([\"date\",\"symbol\",\"expiration\"]):\n",
    "        if len(g) < min_parity_pairs:\n",
    "            continue\n",
    "        tau = float(g[\"tau\"].iloc[0])\n",
    "        res = parity_infer_F_DF(g[[\"strike\",\"C_mid\",\"P_mid\"]])\n",
    "        if res is None:\n",
    "            continue\n",
    "        F, DF = res\n",
    "        r = -math.log(max(DF, 1e-12)) / max(tau, 1e-12)\n",
    "\n",
    "        gg = pvt[(pvt[\"date\"]==date)&(pvt[\"symbol\"]==sym)&(pvt[\"expiration\"]==exp)].copy()\n",
    "        gg[\"F\"], gg[\"DF\"], gg[\"r\"] = F, DF, r\n",
    "        recs.append(gg)\n",
    "        parity_rows.append({\"date\":date,\"symbol\":sym,\"expiration\":exp,\"tau\":tau,\"F\":F,\"DF\":DF,\"r\":r,\"n_pairs\":len(g)})\n",
    "\n",
    "    if not recs:\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    calls = pd.concat(recs, ignore_index=True)\n",
    "    parity_df = pd.DataFrame(parity_rows)\n",
    "\n",
    "    # market B76 IVs (calls only)\n",
    "    calls = calls[calls[\"C_mid\"].notna()].copy()\n",
    "    calls[\"sigma_mkt_b76\"] = calls.apply(\n",
    "        lambda r: b76_iv_from_price(r[\"C_mid\"], r[\"F\"], r[\"strike\"], r[\"tau\"], r[\"r\"]), axis=1\n",
    "    )\n",
    "    calls = calls.dropna(subset=[\"sigma_mkt_b76\"]).copy()\n",
    "    if calls.empty: return pd.DataFrame(), parity_df\n",
    "\n",
    "    calls[\"moneyness_F\"] = calls[\"strike\"] / calls[\"F\"]\n",
    "    # bucket default; caller may overwrite with custom centers\n",
    "    calls[\"bucket\"] = calls[\"tau\"].apply(assign_bucket)\n",
    "    return calls, parity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec17743-e7a4-4e57-8eb7-378d244de17e",
   "metadata": {},
   "source": [
    "## 8. Calibration helpers (SciPy + fallback)\n",
    "\n",
    "We fit model parameters **per (day × maturity bucket)** by minimizing **call price SSE** over the cross-section.\n",
    "\n",
    "### Objective (generic)\n",
    "Given fixed inputs $\\{F_i, K_i, \\tau_i, r_i, C^{\\text{mkt}}_i\\}_{i\\in\\mathcal{B}}$ for a bucket $\\mathcal{B}$ and a model $M(\\cdot;\\,\\theta)$,\n",
    "$$\n",
    "\\min_{\\theta}\\;\\;\\text{SSE}(\\theta)\n",
    "\\;=\\;\n",
    "\\sum_{i\\in\\mathcal{B}}\n",
    "\\Big(M(F_i,K_i,\\tau_i,r_i;\\theta) - C^{\\text{mkt}}_i\\Big)^2.\n",
    "$$\n",
    "Each model (JD/Heston) provides its **parameter vector** $\\theta$, **bounds**, and an **initial guess** based on ATM IV.\n",
    "\n",
    "### Solver strategy\n",
    "- **Primary (if SciPy is available):** use **L-BFGS-B** with box constraints (bounds), `maxiter≈200`, and early stop on small gradient/step.\n",
    "- **Fallback (no SciPy):** evaluate a **small local grid** around the initial guess (±20% of each bounded range, ~7 points per dim) and **pick the best grid point** (lowest SSE).\n",
    "\n",
    "### Numerical guards (penalty = large SSE)\n",
    "- Enforce parameter domains (e.g., $\\sigma>0$, $\\lambda\\ge0$, $\\delta_J>0$, $\\kappa>0$, $\\theta>0$, $\\sigma_v>0$, $\\rho\\in[-0.999,0]$, $v_0>0$).\n",
    "- If pricing fails/overflows, return a large SSE so the optimizer avoids that region.\n",
    "- **JD:** truncate Poisson mixture when cumulative mass $>1-\\varepsilon$ (e.g., $\\varepsilon=10^{-8}$) or at $n_{\\max}$ (50–80).\n",
    "- **Heston:** use the **little Heston trap** CF and **Simpson’s rule** on a stable grid $u\\in(0,u_{\\max})$.\n",
    "\n",
    "### Outputs (per bucket)\n",
    "- **Params:** best-fit $\\hat\\theta$ as a dict.  \n",
    "- **Fit quality:** final SSE value (for diagnostics).  \n",
    "These parameters are then used to **price the cross-section**, invert to **B76 IV**, and compute the **IVRMSE** slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10d3673c-ff46-40f9-a309-79b750e4c3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Calibration helpers (JD & Heston)\n",
    "# ============================================================\n",
    "\n",
    "def _minimize(func, x0, bounds):\n",
    "    \"\"\"SciPy L-BFGS-B; fall back to a small local grid around x0 if SciPy missing.\"\"\"\n",
    "    if _HAVE_SCIPY:\n",
    "        res = minimize(func, x0, method=\"L-BFGS-B\", bounds=bounds, options={\"maxiter\": 200})\n",
    "        return (res.x if res.success else x0)\n",
    "    x0 = np.array(x0, dtype=float)\n",
    "    grids = []\n",
    "    for (lo, hi), xi in zip(bounds, x0):\n",
    "        span = (hi - lo)\n",
    "        g = np.linspace(max(lo, xi - 0.2*span), min(hi, xi + 0.2*span), 7)\n",
    "        grids.append(g)\n",
    "    mesh = np.meshgrid(*grids, indexing=\"ij\")\n",
    "    cand = np.stack([m.ravel() for m in mesh], axis=1)\n",
    "    vals = np.array([func(p) for p in cand])\n",
    "    return cand[int(np.argmin(vals))]\n",
    "\n",
    "def calibrate_jd_bucket(calls_bucket: pd.DataFrame) -> Tuple[Dict[str, float], float]:\n",
    "    \"\"\"Fit JD params (sigma, lam, muJ, deltaJ) by price SSE on the bucket cross-section.\"\"\"\n",
    "    if calls_bucket.empty: return {}, np.inf\n",
    "    atm_iv = float(np.median(calls_bucket[\"sigma_mkt_b76\"].values))\n",
    "\n",
    "    def sse_vec(p):\n",
    "        sigma, lam, muJ, dJ = p\n",
    "        if sigma <= 0 or lam < 0 or dJ <= 0: return 1e18\n",
    "        prices = np.array([\n",
    "            merton_price_call_b76(float(r0[\"F\"]), float(r0[\"strike\"]), float(r0[\"tau\"]), float(r0[\"r\"]),\n",
    "                                  sigma, lam, muJ, dJ)\n",
    "            for _, r0 in calls_bucket.iterrows()\n",
    "        ], dtype=float)\n",
    "        err = prices - calls_bucket[\"C_mid\"].values\n",
    "        return float(np.dot(err, err))\n",
    "\n",
    "    x0 = np.array([max(0.02, atm_iv), 0.1, -0.02, 0.10], dtype=float)\n",
    "    bounds = [(0.01, 3.0), (0.0, 5.0), (-0.5, 0.5), (0.01, 1.0)]\n",
    "    p = _minimize(sse_vec, x0, bounds)\n",
    "    params = {\"sigma\": float(p[0]), \"lam\": float(p[1]), \"muJ\": float(p[2]), \"deltaJ\": float(p[3])}\n",
    "    sse_final = sse_vec([params[\"sigma\"], params[\"lam\"], params[\"muJ\"], params[\"deltaJ\"]])\n",
    "    return params, sse_final\n",
    "\n",
    "def calibrate_heston_bucket(calls_bucket: pd.DataFrame,\n",
    "                            u_max: float = 100.0, n_points: int = 501) -> Tuple[Dict[str, float], float]:\n",
    "    \"\"\"Fit Heston params (kappa, theta, sigma_v, rho, v0) by price SSE on the bucket cross-section.\"\"\"\n",
    "    if calls_bucket.empty: return {}, np.inf\n",
    "    atm_iv = float(np.median(calls_bucket[\"sigma_mkt_b76\"].values))\n",
    "\n",
    "    def sse_vec(p):\n",
    "        kappa, theta, sigma_v, rho, v0 = p\n",
    "        if kappa <= 0 or theta <= 0 or sigma_v <= 0 or not (-0.999 <= rho <= 0.0) or v0 <= 0:\n",
    "            return 1e18\n",
    "        params = {\"kappa\":kappa, \"theta\":theta, \"sigma_v\":sigma_v, \"rho\":rho, \"v0\":v0}\n",
    "        prices = np.array([\n",
    "            heston_price_call(float(r0[\"F\"]), float(r0[\"strike\"]), float(r0[\"tau\"]), float(r0[\"r\"]), params,\n",
    "                              u_max=u_max, n_points=n_points)\n",
    "            for _, r0 in calls_bucket.iterrows()\n",
    "        ], dtype=float)\n",
    "        err = prices - calls_bucket[\"C_mid\"].values\n",
    "        return float(np.dot(err, err))\n",
    "\n",
    "    v0_0 = max(1e-4, atm_iv*atm_iv)\n",
    "    x0 = np.array([2.0, max(1e-4, v0_0), 0.5, -0.5, v0_0], dtype=float)\n",
    "    bounds = [(0.05, 10.0), (1e-4, 2.0), (1e-3, 3.0), (-0.999, 0.0), (1e-4, 3.0)]\n",
    "    p = _minimize(sse_vec, x0, bounds)\n",
    "    params = {\"kappa\": float(p[0]), \"theta\": float(p[1]), \"sigma_v\": float(p[2]), \"rho\": float(p[3]), \"v0\": float(p[4])}\n",
    "    sse_final = sse_vec([params[\"kappa\"], params[\"theta\"], params[\"sigma_v\"], params[\"rho\"], params[\"v0\"]])\n",
    "    return params, sse_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43444354-db62-4528-a411-277d20feccb2",
   "metadata": {},
   "source": [
    "## 9. IVRMSE computation & aggregation\n",
    "\n",
    "**Per (day × bucket):**  \n",
    "- **BS/Black–76.** The model IV is the **single fitted** $\\hat\\sigma$ for that bucket. Compare directly to market IVs:\n",
    "$$\n",
    "\\text{IVRMSE}_{\\text{BS},\\,b,d}\n",
    "=\\sqrt{\\frac{1}{n_{b,d}}\\sum_{i\\in(b,d)}\n",
    "\\big(\\hat\\sigma-\\sigma^{\\text{mkt}}_i\\big)^2}\\times 1000.\n",
    "$$\n",
    "\n",
    "- **JD / Heston.** For each strike $i$, **price** with the calibrated model, then **invert** that price to a Black–76 IV $\\sigma^{\\text{mdl}}_i$, and compare to the market IV:\n",
    "$$\n",
    "\\text{IVRMSE}_{\\text{mdl},\\,b,d}\n",
    "=\\sqrt{\\frac{1}{n_{b,d}}\\sum_{i\\in(b,d)}\n",
    "\\big(\\sigma^{\\text{mdl}}_i-\\sigma^{\\text{mkt}}_i\\big)^2}\\times 1000,\n",
    "\\quad \\text{mdl}\\in\\{\\text{JD},\\text{Heston}\\}.\n",
    "$$\n",
    "\n",
    "Here $n_{b,d}$ is the number of **usable call contracts** in bucket $b$ on day $d$ (after cleaning and successful IV inversion).\n",
    "\n",
    "**Report slices (computed separately):**  \n",
    "- **Whole**: all strikes in the bucket.  \n",
    "- **$m<1$**: $m=K/F<1$.  \n",
    "- **$m>1$**: $m=K/F>1$.  \n",
    "- **$m>1.03$**: deeper OTM calls.\n",
    "\n",
    "---\n",
    "\n",
    "### Aggregation over a period (primary & secondary)\n",
    "\n",
    "Let $\\mathcal{D}_b$ be the set of trading days that produced a valid IVRMSE for bucket $b$, and let $R_{b,d}$ denote that **daily IVRMSE** (for the chosen slice) on day $d$.\n",
    "\n",
    "**Primary — Equal-day mean (each day counts once):**\n",
    "$$\n",
    "\\overline{R}^{\\text{equal}}_{b}\n",
    "=\\frac{1}{|\\mathcal{D}_b|}\\sum_{d\\in\\mathcal{D}_b} R_{b,d}.\n",
    "$$\n",
    "\n",
    "**Secondary — Pooled (contract-weighted) IVRMSE**  \n",
    "(= pooling **all contracts** across the period in bucket $b$):\n",
    "$$\n",
    "\\overline{R}^{\\text{pooled}}_{b}\n",
    "=\\sqrt{\\frac{\\sum_{d\\in\\mathcal{D}_b}\\sum_{i\\in(b,d)}\n",
    "\\big(\\Delta\\sigma_{i}\\big)^2}{\\sum_{d\\in\\mathcal{D}_b} n_{b,d}}}\\times 1000,\n",
    "\\qquad\n",
    "\\Delta\\sigma_{i} =\n",
    "\\begin{cases}\n",
    "\\hat\\sigma-\\sigma^{\\text{mkt}}_i,& \\text{BS}\\\\[2pt]\n",
    "\\sigma^{\\text{mdl}}_i-\\sigma^{\\text{mkt}}_i,& \\text{JD/Heston}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Equivalent “RMSE pooling” using only daily IVRMSE and counts:**\n",
    "$$\n",
    "\\overline{R}^{\\text{pooled}}_{b}\n",
    "=\\sqrt{\\frac{\\sum_{d\\in\\mathcal{D}_b} n_{b,d}\\,\\big(R_{b,d}/1000\\big)^2}{\\sum_{d\\in\\mathcal{D}_b} n_{b,d}}}\\times 1000.\n",
    "$$\n",
    "\n",
    "**Units & notes.**  \n",
    "- All IVRMSE values are reported $\\times\\,1000$ (as in the reference tables).  \n",
    "- Days with **no valid bucket** are omitted from $\\mathcal{D}_b$.  \n",
    "- The **equal-day mean** is the recommended primary metric (prevents heavy-volume days from dominating); the **pooled** metric is a useful secondary check.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c66895b2-7fb1-4b53-8bb4-feece617fb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# IVRMSE bookkeeping\n",
    "# ============================================================\n",
    "\n",
    "def _ivrmse_vs_constant_sigma(calls_bucket: pd.DataFrame, sig_hat: float) -> Dict[str, float]:\n",
    "    \"\"\"IVRMSE slices when model IV is constant σ̂ across strikes in bucket.\"\"\"\n",
    "    def rmse(sub: pd.DataFrame) -> float:\n",
    "        if len(sub) == 0: return np.nan\n",
    "        return float(np.sqrt(np.mean((sub[\"sigma_mkt_b76\"].values - sig_hat)**2)))\n",
    "    return {\n",
    "        \"whole\": rmse(calls_bucket),\n",
    "        \"<1\":    rmse(calls_bucket[calls_bucket[\"moneyness_F\"] < 1.0]),\n",
    "        \">1\":    rmse(calls_bucket[calls_bucket[\"moneyness_F\"] > 1.0]),\n",
    "        \">1.03\": rmse(calls_bucket[calls_bucket[\"moneyness_F\"] > 1.03]),\n",
    "    }\n",
    "\n",
    "def _ivrmse_vs_model_prices(calls_bucket: pd.DataFrame, price_fn) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Price with a model → invert to B76 IV → compare to market IVs.\n",
    "    Keep only rows where inversion succeeds.\n",
    "    \"\"\"\n",
    "    sig_model, keep = [], []\n",
    "    for _, r0 in calls_bucket.iterrows():\n",
    "        pm = price_fn(F=float(r0[\"F\"]), K=float(r0[\"strike\"]), tau=float(r0[\"tau\"]), r=float(r0[\"r\"]))\n",
    "        s  = b76_iv_from_price(pm, float(r0[\"F\"]), float(r0[\"strike\"]), float(r0[\"tau\"]), float(r0[\"r\"]))\n",
    "        if s is not None:\n",
    "            sig_model.append(s); keep.append(True)\n",
    "        else:\n",
    "            keep.append(False)\n",
    "    if not any(keep):\n",
    "        return {\"whole\": np.nan, \"<1\": np.nan, \">1\": np.nan, \">1.03\": np.nan}\n",
    "    cb = calls_bucket.loc[np.array(keep, dtype=bool)].copy()\n",
    "    cb[\"sigma_model_b76\"] = np.array(sig_model, dtype=float)\n",
    "\n",
    "    def rmse(sub: pd.DataFrame) -> float:\n",
    "        if len(sub) == 0: return np.nan\n",
    "        return float(np.sqrt(np.mean((sub[\"sigma_model_b76\"].values - sub[\"sigma_mkt_b76\"].values)**2)))\n",
    "    return {\n",
    "        \"whole\": rmse(cb),\n",
    "        \"<1\":    rmse(cb[cb[\"moneyness_F\"] < 1.0]),\n",
    "        \">1\":    rmse(cb[cb[\"moneyness_F\"] > 1.0]),\n",
    "        \">1.03\": rmse(cb[cb[\"moneyness_F\"] > 1.03]),\n",
    "    }\n",
    "\n",
    "def _pooled_rmse_x1000(block: pd.DataFrame, iv_col: str, weight_col: str = \"N\") -> float:\n",
    "    \"\"\"\n",
    "    Contract-weighted pooled RMSE across rows in `block`, ignoring NaNs.\n",
    "    Returns NaN only if no valid (value, weight) pairs remain after masking\n",
    "    or if total weight is zero.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    x = block[iv_col].to_numpy(dtype=float)           # IVRMSE ×1000 (may contain NaN)\n",
    "    w = block[weight_col].to_numpy(dtype=float)       # weights (contract counts)\n",
    "    m = np.isfinite(x) & np.isfinite(w) & (w > 0)     # keep only valid pairs\n",
    "    if not m.any():\n",
    "        return np.nan\n",
    "    x_raw = x[m] / 1000.0                             # back to raw RMSE\n",
    "    w_use = w[m]\n",
    "    return float(np.sqrt((w_use * (x_raw ** 2)).sum() / w_use.sum()) * 1000.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655cabff-8634-492a-b56f-2e11404bf4d9",
   "metadata": {},
   "source": [
    "## 10. Period summarizer (daily loop, saving)\n",
    "\n",
    "For each **trading day** in the selected period:\n",
    "\n",
    "1. **Prepare calls & buckets**  \n",
    "   - Clean quotes, form call–put pairs, infer $(F,DF,r)$ per expiry via parity.  \n",
    "   - Compute market Black–76 IVs for calls.  \n",
    "   - Map each contract to the nearest **maturity bucket** (e.g., 14d / 28d / 56d).\n",
    "\n",
    "2. **Calibrate per bucket (price SSE)**  \n",
    "   - **BS/Black–76:** fit a single $\\hat\\sigma$.  \n",
    "   - **Merton JD:** fit $(\\sigma,\\lambda,\\mu_J,\\delta_J)$.  \n",
    "   - **Heston SV:** fit $(\\kappa,\\theta,\\sigma_v,\\rho,v_0)$ using CF + Simpson integrals.\n",
    "\n",
    "3. **Evaluate IVRMSE slices**  \n",
    "   - **BS:** compare $\\hat\\sigma$ directly to market IVs.  \n",
    "   - **JD/Heston:** price each strike, **invert to Black–76 IV**, compare to market IVs.  \n",
    "   - Report slices: **Whole**, **$m<1$**, **$m>1$**, **$m>1.03$** (with $m=K/F$).\n",
    "\n",
    "4. **Daily compact log (Whole × model)**  \n",
    "   - After all buckets that day, print one line with the **pooled (contract-weighted) Whole IVRMSE** per model and total counts.\n",
    "\n",
    "---\n",
    "\n",
    "### Saved outputs (if `out_dir` is provided)\n",
    "\n",
    "- **`daily_ivrmse.csv`** — rows per *(day, bucket)* with `N` and IVRMSE slices for each model.  \n",
    "- **`equal_day_mean.csv`** — **primary** metric: equal-day mean IVRMSE per bucket.  \n",
    "- **`pooled.csv`** — **secondary** metric: pooled (contract-weighted) IVRMSE per bucket.  \n",
    "- **`daily_log.txt`** — one-line **pooled Whole** summary per day (quick progress/diagnostics).\n",
    "\n",
    "The publication table is built from `equal_day_mean.csv` (primary) and cross-checked with `pooled.csv` (secondary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a368b86-f18a-4f65-a032-bee51e3ca1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Main entry: summarize symbol over a period with saving\n",
    "# ============================================================\n",
    "\n",
    "def summarize_symbol_period_ivrmse(\n",
    "    df_all: pd.DataFrame,\n",
    "    symbol: str = \"SPY\",\n",
    "    start_date: str = \"2025-04-01\",\n",
    "    end_date:   str = \"2025-06-30\",\n",
    "    buckets: List[int] = [14, 28, 56],\n",
    "    min_parity_pairs: int = 4,\n",
    "    tau_floor_days: int = 3,\n",
    "    run_bs: bool = True,\n",
    "    run_jd: bool = True,\n",
    "    run_heston: bool = True,\n",
    "    show_progress: bool = True,\n",
    "    print_daily: bool = True,\n",
    "    out_dir: Optional[str] = None,\n",
    ") -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    ONE summary for a symbol over a period (per bucket):\n",
    "      • Primary  = equal-day mean IVRMSE (each day counts once)\n",
    "      • Secondary= pooled/N-weighted IVRMSE (every contract counts)\n",
    "    Saves: daily table, equal_day_mean, pooled, and a daily log (one line/day).\n",
    "    \"\"\"\n",
    "    # Output folder & run config\n",
    "    outp = None\n",
    "    log_fp = None\n",
    "    if out_dir is not None:\n",
    "        outp = Path(out_dir)\n",
    "        outp.mkdir(parents=True, exist_ok=True)\n",
    "        log_fp = (outp / \"daily_log.txt\").open(\"w\", encoding=\"utf-8\")\n",
    "        (outp / \"run_config.txt\").write_text(\n",
    "            f\"symbol={symbol}\\\\nperiod={start_date}..{end_date}\\\\n\"\n",
    "            f\"buckets={buckets}\\\\nmin_parity_pairs={min_parity_pairs}\\\\n\"\n",
    "            f\"tau_floor_days={tau_floor_days}\\\\nrun_bs={run_bs} run_jd={run_jd} run_heston={run_heston}\\\\n\",\n",
    "            encoding=\"utf-8\"\n",
    "        )\n",
    "\n",
    "    # Filter to symbol & period\n",
    "    df = df_all.copy()\n",
    "    sym_col = \"act_symbol\" if \"act_symbol\" in df.columns else \"symbol\"\n",
    "    if sym_col not in df.columns:\n",
    "        if log_fp: log_fp.close()\n",
    "        raise ValueError(\"Expected 'act_symbol' or 'symbol' in DataFrame.\")\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"]).dt.normalize()\n",
    "    mask = (df[sym_col] == symbol) & (df[\"date\"] >= pd.Timestamp(start_date)) & (df[\"date\"] <= pd.Timestamp(end_date))\n",
    "    df = df.loc[mask].copy()\n",
    "    if df.empty:\n",
    "        if log_fp: log_fp.close()\n",
    "        raise ValueError(f\"No rows for {symbol} in [{start_date}, {end_date}].\")\n",
    "\n",
    "    # Bucket mapper using requested centers\n",
    "    def assign_bucket_centers(tau_years: float) -> str:\n",
    "        days = tau_years * 365.0\n",
    "        i = int(np.argmin([abs(days - c) for c in buckets]))\n",
    "        return f\"{buckets[i]}d\"\n",
    "\n",
    "    # Iterate by day with progress\n",
    "    days = sorted(df[\"date\"].unique())\n",
    "    iterator = days\n",
    "    if show_progress:\n",
    "        try:\n",
    "            from tqdm.auto import tqdm\n",
    "            iterator = tqdm(days, desc=f\"{symbol} {pd.Timestamp(start_date).date()}→{pd.Timestamp(end_date).date()}\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    daily_rows = []\n",
    "\n",
    "    for day in iterator:\n",
    "        df_day = df[df[\"date\"] == day]\n",
    "        calls, _ = prepare_calls_one_day_symbol(df_day, min_parity_pairs=min_parity_pairs, tau_floor_days=tau_floor_days)\n",
    "        if calls.empty:\n",
    "            msg = f\"[{pd.Timestamp(day).date()}] no valid pairs/contracts after filters\"\n",
    "            if print_daily: print(msg)\n",
    "            if log_fp: print(msg, file=log_fp)\n",
    "            continue\n",
    "\n",
    "        calls[\"bucket\"] = calls[\"tau\"].apply(assign_bucket_centers)\n",
    "\n",
    "        day_rows = []\n",
    "        for bucket, g in calls.groupby(\"bucket\"):\n",
    "            row = {\"date\": pd.Timestamp(day), \"bucket\": bucket, \"N\": int(len(g))}\n",
    "\n",
    "            # BS/B76 baseline (1-σ)\n",
    "            if run_bs:\n",
    "                sig_hat = fit_sigma_bucket(g)\n",
    "                ivs = _ivrmse_vs_constant_sigma(g, sig_hat)\n",
    "                row.update({\n",
    "                    \"BS_IVRMSE_x1000_Whole\":  ivs[\"whole\"] * 1000 if np.isfinite(ivs[\"whole\"]) else np.nan,\n",
    "                    \"BS_IVRMSE_x1000_<1\":     ivs[\"<1\"]    * 1000 if np.isfinite(ivs[\"<1\"])    else np.nan,\n",
    "                    \"BS_IVRMSE_x1000_>1\":     ivs[\">1\"]    * 1000 if np.isfinite(ivs[\">1\"])    else np.nan,\n",
    "                    \"BS_IVRMSE_x1000_>1.03\":  ivs[\">1.03\"] * 1000 if np.isfinite(ivs[\">1.03\"]) else np.nan,\n",
    "                })\n",
    "\n",
    "            # JD baseline\n",
    "            if run_jd:\n",
    "                jd_params, _ = calibrate_jd_bucket(g)\n",
    "                def jd_price(F,K,tau,r):\n",
    "                    return merton_price_call_b76(F,K,tau,r, jd_params[\"sigma\"], jd_params[\"lam\"], jd_params[\"muJ\"], jd_params[\"deltaJ\"])\n",
    "                ivs = _ivrmse_vs_model_prices(g, jd_price)\n",
    "                row.update({\n",
    "                    \"JD_IVRMSE_x1000_Whole\":  ivs[\"whole\"] * 1000 if np.isfinite(ivs[\"whole\"]) else np.nan,\n",
    "                    \"JD_IVRMSE_x1000_<1\":     ivs[\"<1\"]    * 1000 if np.isfinite(ivs[\"<1\"])    else np.nan,\n",
    "                    \"JD_IVRMSE_x1000_>1\":     ivs[\">1\"]    * 1000 if np.isfinite(ivs[\">1\"])    else np.nan,\n",
    "                    \"JD_IVRMSE_x1000_>1.03\":  ivs[\">1.03\"] * 1000 if np.isfinite(ivs[\">1.03\"]) else np.nan,\n",
    "                })\n",
    "\n",
    "            # Heston baseline\n",
    "            if run_heston:\n",
    "                h_params, _ = calibrate_heston_bucket(g, u_max=100.0, n_points=501)  # stable Simpson settings\n",
    "                def h_price(F,K,tau,r):\n",
    "                    return heston_price_call(F,K,tau,r, h_params, u_max=100.0, n_points=501)\n",
    "                ivs = _ivrmse_vs_model_prices(g, h_price)\n",
    "                row.update({\n",
    "                    \"Heston_IVRMSE_x1000_Whole\":  ivs[\"whole\"] * 1000 if np.isfinite(ivs[\"whole\"]) else np.nan,\n",
    "                    \"Heston_IVRMSE_x1000_<1\":     ivs[\"<1\"]    * 1000 if np.isfinite(ivs[\"<1\"])    else np.nan,\n",
    "                    \"Heston_IVRMSE_x1000_>1\":     ivs[\">1\"]    * 1000 if np.isfinite(ivs[\">1\"])    else np.nan,\n",
    "                    \"Heston_IVRMSE_x1000_>1.03\":  ivs[\">1.03\"] * 1000 if np.isfinite(ivs[\">1.03\"]) else np.nan,\n",
    "                })\n",
    "\n",
    "            day_rows.append(row)\n",
    "\n",
    "        if not day_rows:\n",
    "            msg = f\"[{pd.Timestamp(day).date()}] no valid buckets\"\n",
    "            if print_daily: print(msg)\n",
    "            if log_fp: print(msg, file=log_fp)\n",
    "            continue\n",
    "\n",
    "        daily_rows.extend(day_rows)\n",
    "\n",
    "        # One compact line per day — pooled across buckets (Whole slice only)\n",
    "        msg_parts = []\n",
    "        day_df = pd.DataFrame(day_rows)\n",
    "        for model, col in [(\"BS\", \"BS_IVRMSE_x1000_Whole\"),\n",
    "                           (\"JD\", \"JD_IVRMSE_x1000_Whole\"),\n",
    "                           (\"Heston\", \"Heston_IVRMSE_x1000_Whole\")]:\n",
    "            if col in day_df.columns:\n",
    "                pooled = _pooled_rmse_x1000(day_df[[\"N\", col]].rename(columns={col: \"val\"}), \"val\")\n",
    "                msg_parts.append(f\"{model}={round(float(pooled),1) if pd.notna(pooled) else 'NA'}\")\n",
    "        msg = f\"[{pd.Timestamp(day).date()}] pooled Whole x1000: \" + \", \".join(msg_parts)\n",
    "        if print_daily: print(msg)\n",
    "        if log_fp: print(msg, file=log_fp)\n",
    "\n",
    "    if log_fp: log_fp.close()\n",
    "\n",
    "    if not daily_rows:\n",
    "        raise RuntimeError(\"No valid (day,bucket) rows — check filters or min_parity_pairs/tau_floor_days.\")\n",
    "\n",
    "    daily = pd.DataFrame(daily_rows)\n",
    "\n",
    "    # ---- Primary: equal-day mean per bucket (each day counts once) ----\n",
    "    iv_cols = [c for c in daily.columns if c.endswith(\"_IVRMSE_x1000_Whole\")\n",
    "                                     or c.endswith(\"_IVRMSE_x1000_<1\")\n",
    "                                     or c.endswith(\"_IVRMSE_x1000_>1\")\n",
    "                                     or c.endswith(\"_IVRMSE_x1000_>1.03\")]\n",
    "    equal_day_mean = (daily.groupby(\"bucket\", as_index=False)[iv_cols].mean())\n",
    "    # Coverage diagnostics\n",
    "    days_used = daily.groupby(\"bucket\")[\"date\"].nunique().rename(\"days_used\").reset_index()\n",
    "    N_total   = daily.groupby(\"bucket\")[\"N\"].sum().rename(\"N_total\").reset_index()\n",
    "    equal_day_mean = (equal_day_mean.merge(days_used, on=\"bucket\")\n",
    "                                   .merge(N_total, on=\"bucket\")\n",
    "                                   .sort_values(\"bucket\"))\n",
    "\n",
    "    # ---- Secondary: pooled/N-weighted per bucket ----\n",
    "    pooled_rows = []\n",
    "    for b, g in daily.groupby(\"bucket\"):\n",
    "        row = {\"bucket\": b, \"days_used\": int(g[\"date\"].nunique()), \"N_total\": int(g[\"N\"].sum())}\n",
    "        for col in iv_cols:\n",
    "            row[col] = _pooled_rmse_x1000(g[[\"N\", col]].rename(columns={col: \"val\"}), \"val\")\n",
    "        pooled_rows.append(row)\n",
    "    pooled = pd.DataFrame(pooled_rows).sort_values(\"bucket\")\n",
    "\n",
    "    # Save outputs\n",
    "    if outp is not None:\n",
    "        daily.to_csv(outp / \"daily_ivrmse.csv\", index=False)\n",
    "        equal_day_mean.to_csv(outp / \"equal_day_mean.csv\", index=False)\n",
    "        pooled.to_csv(outp / \"pooled.csv\", index=False)\n",
    "\n",
    "    return {\"daily\": daily, \"equal_day_mean\": equal_day_mean, \"pooled\": pooled}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e04a02-8ebe-4727-a65c-b6773b83fe20",
   "metadata": {},
   "source": [
    "## 11. Publication-style table\n",
    "\n",
    "**Goal.** Present model accuracy (IVRMSE ×1000) in a compact, reader-friendly table that mirrors common practice in the literature.\n",
    "\n",
    "**Layout.**\n",
    "- **Rows:** by **moneyness slice** (Whole, $m<1$, $m>1$, $m>1.03$) and **maturity bucket** (e.g., 14d / 28d / 56d).  \n",
    "- **Columns:** **BS**, **JD**, **SV (Heston)** — each entry is IVRMSE ×1000.\n",
    "\n",
    "**Source of values.**\n",
    "- Use the **primary** metric (the **equal-day mean** per bucket) for the table.  \n",
    "- Optionally report the **secondary** metric (contract-weighted **pooled** IVRMSE) in an appendix or robustness table.\n",
    "\n",
    "**Rendering & export.**\n",
    "- If `out_dir` is provided, save both:\n",
    "  - **CSV**: machine-readable table.\n",
    "  - **Markdown**: human-readable version with formatting.\n",
    "- In the Markdown table, **bold the minimum in each row** (best model for that slice/bucket) to improve readability.\n",
    "\n",
    "**Notes.**\n",
    "- All numbers are **scaled by 1000** (e.g., 7.5 → IVRMSE of 0.0075).  \n",
    "- Days/buckets with no valid quotes or failed inversions are omitted from averaging.  \n",
    "- The table reflects the **same data filters** used in the baselines (min paired strikes, $\\tau$ floor, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9d6b8fb-510a-4a1e-b081-a8d7463e1786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Publication-style table (CSV + Markdown with bold minima)\n",
    "# ============================================================\n",
    "\n",
    "def make_publication_table(res: Dict[str, pd.DataFrame],\n",
    "                           symbol: str = \"SPY\",\n",
    "                           measure: str = \"equal\",          # \"equal\" (primary) or \"pooled\" (secondary)\n",
    "                           buckets: List[int] = (14, 28, 56),\n",
    "                           decimals: int = 2,\n",
    "                           out_dir: Optional[str] = None,\n",
    "                           basename: str = \"table_ivrmse\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a paper-style table matching the reference format:\n",
    "      Sections: Whole sample / Moneyness <1 / >1 / >1.03\n",
    "      Rows: one per bucket like 'SPY (τ=14d)'\n",
    "      Columns: BS, JD, SV (Heston)\n",
    "    Saves CSV + Markdown (bolds the row minimum) if out_dir is set.\n",
    "    \"\"\"\n",
    "    if measure not in (\"equal\", \"pooled\"):\n",
    "        raise ValueError(\"measure must be 'equal' or 'pooled'.\")\n",
    "\n",
    "    df_src = res[\"equal_day_mean\"] if measure == \"equal\" else res[\"pooled\"]\n",
    "    if df_src is None or df_src.empty:\n",
    "        raise ValueError(\"Source summary is empty.\")\n",
    "\n",
    "    present = set(df_src.columns)\n",
    "    models = [m for m, prefix in [(\"BS\",\"BS\"), (\"JD\",\"JD\"), (\"SV\",\"Heston\")]\n",
    "              if any(col.startswith(f\"{prefix}_IVRMSE_x1000\") for col in present)]\n",
    "    model_to_prefix = {\"BS\":\"BS\", \"JD\":\"JD\", \"SV\":\"Heston\"}\n",
    "\n",
    "    sections = [(\"Whole sample\", \"Whole\"),\n",
    "                (\"Moneyness <1\", \"<1\"),\n",
    "                (\"Moneyness >1\", \">1\"),\n",
    "                (\"Moneyness >1.03\", \">1.03\")]\n",
    "    bucket_labels = [f\"{d}d\" for d in buckets]\n",
    "\n",
    "    rows = []\n",
    "    for section_name, suffix in sections:\n",
    "        for d in bucket_labels:\n",
    "            row = {\"Moneyness\": section_name, \"Asset\": f\"{symbol} (τ={d})\"}\n",
    "            sub = df_src[df_src[\"bucket\"] == d]\n",
    "            if sub.empty:\n",
    "                for m in models: row[m] = np.nan\n",
    "            else:\n",
    "                for m in models:\n",
    "                    prefix = model_to_prefix[m]\n",
    "                    col = f\"{prefix}_IVRMSE_x1000_{suffix}\"\n",
    "                    row[m] = float(sub[col].iloc[0]) if col in sub.columns and pd.notna(sub[col].iloc[0]) else np.nan\n",
    "            rows.append(row)\n",
    "\n",
    "    table = pd.DataFrame(rows)\n",
    "    for m in models:\n",
    "        table[m] = table[m].round(decimals)\n",
    "\n",
    "    if out_dir:\n",
    "        outp = Path(out_dir); outp.mkdir(parents=True, exist_ok=True)\n",
    "        csv_path = outp / f\"{basename}_{measure}.csv\"\n",
    "        table.to_csv(csv_path, index=False)\n",
    "\n",
    "        # Markdown with bold minimum per row\n",
    "        md_rows = []\n",
    "        header = [\"Moneyness\", \"Asset\"] + models\n",
    "        md_rows.append(\"| \" + \" | \".join(header) + \" |\")\n",
    "        md_rows.append(\"| \" + \" | \".join([\"---\"]*len(header)) + \" |\")\n",
    "        for _, r in table.iterrows():\n",
    "            vals = [r[m] for m in models]\n",
    "            not_nan = [i for i,v in enumerate(vals) if pd.notna(v)]\n",
    "            best_idx = None\n",
    "            if not_nan:\n",
    "                best_idx = min(not_nan, key=lambda i: vals[i])\n",
    "            cells = [str(r[\"Moneyness\"]), str(r[\"Asset\"])]\n",
    "            for i, m in enumerate(models):\n",
    "                v = r[m]\n",
    "                if pd.isna(v):\n",
    "                    cells.append(\"\")\n",
    "                else:\n",
    "                    s = f\"{v:.{decimals}f}\"\n",
    "                    cells.append(f\"**{s}**\" if i == best_idx else s)\n",
    "            md_rows.append(\"| \" + \" | \".join(cells) + \" |\")\n",
    "        md_text = \"\\\\n\".join(md_rows)\n",
    "        md_path = outp / f\"{basename}_{measure}.md\"\n",
    "        md_path.write_text(md_text, encoding=\"utf-8\")\n",
    "        print(f\"Saved: {csv_path}\")\n",
    "        print(f\"Saved: {md_path}\")\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96726541-4b76-47cb-a7d9-14ed4b17c67f",
   "metadata": {},
   "source": [
    "### SPY (Benchmark) — Q2 2025 IVRMSE\n",
    " \n",
    "SPY is the SPDR S&P 500 ETF Trust, a widely traded ETF that tracks the S&P 500 index (U.S. large-cap equities). Its options are among the most liquid in the market, making SPY a standard benchmark for model comparisons.\n",
    " \n",
    "Here we report **IVRMSE ×1000** for SPY options over **Q2 2025** (April–June), summarized by maturity buckets and moneyness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5987a03d-074b-4c7a-b087-bee98d6c3f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23130 entries, 0 to 23129\n",
      "Data columns (total 13 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   date        23130 non-null  object \n",
      " 1   act_symbol  23130 non-null  object \n",
      " 2   expiration  23130 non-null  object \n",
      " 3   strike      23130 non-null  float64\n",
      " 4   call_put    23130 non-null  object \n",
      " 5   bid         23130 non-null  float64\n",
      " 6   ask         23130 non-null  float64\n",
      " 7   vol         23130 non-null  float64\n",
      " 8   delta       23130 non-null  float64\n",
      " 9   gamma       23130 non-null  float64\n",
      " 10  theta       23130 non-null  float64\n",
      " 11  vega        23130 non-null  float64\n",
      " 12  rho         23130 non-null  float64\n",
      "dtypes: float64(9), object(4)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./SPY Options 2025.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "121c98b4-30d6-4ccd-9244-4e79f343ade6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e4a3123db3c4ab2910034c1a425205b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SPY 2025-04-01→2025-06-30:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-01] pooled Whole x1000: BS=58.8, JD=36.6, Heston=68.3\n",
      "[2025-04-02] pooled Whole x1000: BS=64.0, JD=48.5, Heston=72.4\n",
      "[2025-04-03] pooled Whole x1000: BS=81.8, JD=25.1, Heston=35.4\n",
      "[2025-04-04] pooled Whole x1000: BS=112.1, JD=11.7, Heston=21.0\n",
      "[2025-04-07] pooled Whole x1000: BS=116.5, JD=11.4, Heston=9.1\n",
      "[2025-04-08] pooled Whole x1000: BS=121.1, JD=11.6, Heston=18.6\n",
      "[2025-04-09] pooled Whole x1000: BS=79.4, JD=16.4, Heston=27.5\n",
      "[2025-04-10] pooled Whole x1000: BS=112.9, JD=16.4, Heston=34.7\n",
      "[2025-04-11] pooled Whole x1000: BS=110.5, JD=21.3, Heston=28.1\n",
      "[2025-04-14] pooled Whole x1000: BS=87.9, JD=32.8, Heston=56.7\n",
      "[2025-04-15] pooled Whole x1000: BS=90.1, JD=34.2, Heston=37.7\n",
      "[2025-04-16] pooled Whole x1000: BS=87.2, JD=28.9, Heston=45.2\n",
      "[2025-04-17] pooled Whole x1000: BS=81.0, JD=32.1, Heston=40.9\n",
      "[2025-04-18] pooled Whole x1000: BS=82.2, JD=29.1, Heston=46.8\n",
      "[2025-04-21] pooled Whole x1000: BS=78.2, JD=21.8, Heston=38.2\n",
      "[2025-04-22] pooled Whole x1000: BS=76.9, JD=25.0, Heston=49.6\n",
      "[2025-04-23] pooled Whole x1000: BS=68.7, JD=17.7, Heston=25.3\n",
      "[2025-04-24] pooled Whole x1000: BS=89.7, JD=57.5, Heston=82.3\n",
      "[2025-04-25] pooled Whole x1000: BS=82.8, JD=52.6, Heston=89.5\n",
      "[2025-04-28] pooled Whole x1000: BS=88.9, JD=46.5, Heston=84.0\n",
      "[2025-04-29] pooled Whole x1000: BS=85.1, JD=60.2, Heston=112.9\n",
      "[2025-04-30] pooled Whole x1000: BS=90.9, JD=66.8, Heston=87.3\n",
      "[2025-05-01] pooled Whole x1000: BS=85.7, JD=55.3, Heston=85.6\n",
      "[2025-05-02] pooled Whole x1000: BS=85.8, JD=63.4, Heston=85.1\n",
      "[2025-05-05] pooled Whole x1000: BS=97.7, JD=83.7, Heston=93.4\n",
      "[2025-05-06] pooled Whole x1000: BS=85.5, JD=60.5, Heston=100.8\n",
      "[2025-05-07] pooled Whole x1000: BS=91.7, JD=52.9, Heston=98.8\n",
      "[2025-05-08] pooled Whole x1000: BS=80.3, JD=63.5, Heston=63.1\n",
      "[2025-05-09] pooled Whole x1000: BS=73.0, JD=53.9, Heston=73.0\n",
      "[2025-05-12] pooled Whole x1000: BS=99.9, JD=79.5, Heston=85.5\n",
      "[2025-05-13] pooled Whole x1000: BS=85.1, JD=62.9, Heston=54.8\n",
      "[2025-05-14] pooled Whole x1000: BS=75.5, JD=51.8, Heston=67.0\n",
      "[2025-05-15] pooled Whole x1000: BS=86.2, JD=72.4, Heston=83.3\n",
      "[2025-05-16] pooled Whole x1000: BS=90.9, JD=75.3, Heston=81.7\n",
      "[2025-05-19] pooled Whole x1000: BS=107.9, JD=93.1, Heston=94.3\n",
      "[2025-05-20] pooled Whole x1000: BS=63.9, JD=39.5, Heston=74.9\n",
      "[2025-05-21] pooled Whole x1000: BS=76.8, JD=50.4, Heston=70.7\n",
      "[2025-05-22] pooled Whole x1000: BS=77.5, JD=47.9, Heston=73.2\n",
      "[2025-05-23] pooled Whole x1000: BS=96.3, JD=69.5, Heston=86.8\n",
      "[2025-05-26] pooled Whole x1000: BS=104.0, JD=72.7, Heston=87.9\n",
      "[2025-05-27] pooled Whole x1000: BS=82.0, JD=45.2, Heston=70.5\n",
      "[2025-05-28] pooled Whole x1000: BS=69.4, JD=54.2, Heston=75.7\n",
      "[2025-05-29] pooled Whole x1000: BS=84.1, JD=37.8, Heston=71.3\n",
      "[2025-05-30] pooled Whole x1000: BS=89.3, JD=64.3, Heston=92.7\n",
      "[2025-06-02] pooled Whole x1000: BS=90.6, JD=49.2, Heston=78.1\n",
      "[2025-06-03] pooled Whole x1000: BS=79.9, JD=37.0, Heston=90.1\n",
      "[2025-06-04] pooled Whole x1000: BS=69.4, JD=21.1, Heston=69.6\n",
      "[2025-06-05] pooled Whole x1000: BS=108.1, JD=31.4, Heston=74.3\n",
      "[2025-06-06] pooled Whole x1000: BS=107.2, JD=45.5, Heston=94.5\n",
      "[2025-06-09] pooled Whole x1000: BS=119.5, JD=102.1, Heston=97.7\n",
      "[2025-06-10] pooled Whole x1000: BS=77.4, JD=14.8, Heston=65.0\n",
      "[2025-06-11] pooled Whole x1000: BS=84.9, JD=40.2, Heston=74.8\n",
      "[2025-06-12] pooled Whole x1000: BS=101.7, JD=29.6, Heston=88.5\n",
      "[2025-06-13] pooled Whole x1000: BS=140.0, JD=102.1, Heston=129.0\n",
      "[2025-06-16] pooled Whole x1000: BS=124.0, JD=53.9, Heston=115.7\n",
      "[2025-06-17] pooled Whole x1000: BS=119.2, JD=62.4, Heston=77.0\n",
      "[2025-06-18] pooled Whole x1000: BS=90.2, JD=36.7, Heston=81.4\n",
      "[2025-06-19] pooled Whole x1000: BS=100.6, JD=65.1, Heston=71.1\n",
      "[2025-06-20] pooled Whole x1000: BS=110.9, JD=76.7, Heston=100.9\n",
      "[2025-06-23] pooled Whole x1000: BS=90.6, JD=64.6, Heston=85.6\n",
      "[2025-06-24] pooled Whole x1000: BS=82.2, JD=22.6, Heston=80.7\n",
      "[2025-06-25] pooled Whole x1000: BS=79.7, JD=36.1, Heston=73.1\n",
      "[2025-06-26] pooled Whole x1000: BS=88.4, JD=58.7, Heston=69.2\n",
      "[2025-06-27] pooled Whole x1000: BS=74.5, JD=34.4, Heston=70.2\n",
      "[2025-06-30] pooled Whole x1000: BS=104.1, JD=87.4, Heston=104.6\n",
      "Saved: SPY_25Q2_baseline/table_ivrmse_equal.csv\n",
      "Saved: SPY_25Q2_baseline/table_ivrmse_equal.md\n",
      "Saved: SPY_25Q2_baseline/table_ivrmse_pooled.csv\n",
      "Saved: SPY_25Q2_baseline/table_ivrmse_pooled.md\n",
      "          Moneyness        Asset      BS     JD     SV\n",
      "0      Whole sample  SPY (τ=14d)  114.52  70.72  94.91\n",
      "1      Whole sample  SPY (τ=28d)   84.58  36.92  48.17\n",
      "2      Whole sample  SPY (τ=56d)   64.19  15.56  56.22\n",
      "3      Moneyness <1  SPY (τ=14d)  143.38  80.20  96.73\n",
      "4      Moneyness <1  SPY (τ=28d)  105.21  38.79  41.53\n",
      "5      Moneyness <1  SPY (τ=56d)   79.29  13.67  68.10\n",
      "6      Moneyness >1  SPY (τ=14d)   57.44  48.16  82.06\n",
      "7      Moneyness >1  SPY (τ=28d)   41.51  23.79  46.54\n",
      "8      Moneyness >1  SPY (τ=56d)   39.76  15.00  36.55\n",
      "9   Moneyness >1.03  SPY (τ=14d)   61.45  52.17  88.85\n",
      "10  Moneyness >1.03  SPY (τ=28d)   43.57  25.34  49.81\n",
      "11  Moneyness >1.03  SPY (τ=56d)   41.92  15.80  38.55\n",
      "          Moneyness        Asset      BS     JD      SV\n",
      "0      Whole sample  SPY (τ=14d)  120.64  83.14  104.12\n",
      "1      Whole sample  SPY (τ=28d)   85.76  42.30   56.43\n",
      "2      Whole sample  SPY (τ=56d)   64.49  19.79   64.32\n",
      "3      Moneyness <1  SPY (τ=14d)  151.98  98.32  115.03\n",
      "4      Moneyness <1  SPY (τ=28d)  106.99  48.69   56.81\n",
      "5      Moneyness <1  SPY (τ=56d)   80.02  20.07   79.23\n",
      "6      Moneyness >1  SPY (τ=14d)   63.77  57.48   87.17\n",
      "7      Moneyness >1  SPY (τ=28d)   45.49  29.55   54.93\n",
      "8      Moneyness >1  SPY (τ=56d)   40.84  19.54   41.79\n",
      "9   Moneyness >1.03  SPY (τ=14d)   68.38  62.35   94.39\n",
      "10  Moneyness >1.03  SPY (τ=28d)   47.84  31.32   58.48\n",
      "11  Moneyness >1.03  SPY (τ=56d)   43.25  20.53   44.00\n"
     ]
    }
   ],
   "source": [
    "res = summarize_symbol_period_ivrmse(\n",
    "    df_all=df,\n",
    "    symbol=\"SPY\",\n",
    "    start_date=\"2025-04-01\",\n",
    "    end_date=\"2025-06-30\",\n",
    "    buckets=[14,28,56],\n",
    "    min_parity_pairs=4,\n",
    "    tau_floor_days=3,\n",
    "    run_bs=True, run_jd=True, run_heston=True,\n",
    "    show_progress=True,\n",
    "    print_daily=True,\n",
    "    out_dir=\"SPY_25Q2_baseline\"      # outputs saved here\n",
    ")\n",
    "\n",
    "# PRIMARY (paper): equal-day mean table\n",
    "tbl_equal = make_publication_table(res, symbol=\"SPY\",\n",
    "                                   measure=\"equal\",\n",
    "                                   buckets=[14,28,56],\n",
    "                                   decimals=2,\n",
    "                                   out_dir=\"SPY_25Q2_baseline\",\n",
    "                                   basename=\"table_ivrmse\")\n",
    "\n",
    "# SECONDARY (robustness): pooled table\n",
    "tbl_pooled = make_publication_table(res, symbol=\"SPY\",\n",
    "                                    measure=\"pooled\",\n",
    "                                    buckets=[14,28,56],\n",
    "                                    decimals=2,\n",
    "                                    out_dir=\"SPY_25Q2_baseline\",\n",
    "                                    basename=\"table_ivrmse\")\n",
    "\n",
    "print(tbl_equal)\n",
    "print(tbl_pooled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49682bba-a21e-4d9b-8591-5c113a041429",
   "metadata": {},
   "source": [
    "### XOP — Q2 2025 IVRMSE\n",
    "\n",
    "**XOP** is the SPDR S&P Oil & Gas Exploration & Production ETF, tracking an equal-weighted index of U.S. E&P companies in the energy sector. \n",
    " \n",
    "Here we report **IVRMSE ×1000** for XOP options over **Q2 2025** (April–June), summarized by maturity buckets and moneyness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5a02ee4-8f7a-4020-b3f0-9c56acbeed3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23106 entries, 0 to 23105\n",
      "Data columns (total 13 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   date        23106 non-null  object \n",
      " 1   act_symbol  23106 non-null  object \n",
      " 2   expiration  23106 non-null  object \n",
      " 3   strike      23106 non-null  float64\n",
      " 4   call_put    23106 non-null  object \n",
      " 5   bid         23106 non-null  float64\n",
      " 6   ask         23106 non-null  float64\n",
      " 7   vol         23106 non-null  float64\n",
      " 8   delta       23106 non-null  float64\n",
      " 9   gamma       23106 non-null  float64\n",
      " 10  theta       23106 non-null  float64\n",
      " 11  vega        23106 non-null  float64\n",
      " 12  rho         23106 non-null  float64\n",
      "dtypes: float64(9), object(4)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./XOP Options 2025.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c112f3b8-8eda-4a93-b5d6-db7bc7052282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "615f0126f5f7475797a1e93546426e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "XOP 2025-04-01→2025-06-30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-01] pooled Whole x1000: BS=71.8, JD=91.6, Heston=95.0\n",
      "[2025-04-02] pooled Whole x1000: BS=52.6, JD=43.3, Heston=67.4\n",
      "[2025-04-03] pooled Whole x1000: BS=72.0, JD=65.1, Heston=66.8\n",
      "[2025-04-04] pooled Whole x1000: BS=51.5, JD=26.0, Heston=26.0\n",
      "[2025-04-07] pooled Whole x1000: BS=63.9, JD=22.4, Heston=28.4\n",
      "[2025-04-08] pooled Whole x1000: BS=63.1, JD=13.4, Heston=13.4\n",
      "[2025-04-09] pooled Whole x1000: BS=90.6, JD=43.7, Heston=50.8\n",
      "[2025-04-10] pooled Whole x1000: BS=77.5, JD=18.7, Heston=26.5\n",
      "[2025-04-11] pooled Whole x1000: BS=93.2, JD=28.6, Heston=54.5\n",
      "[2025-04-14] pooled Whole x1000: BS=104.5, JD=26.4, Heston=69.3\n",
      "[2025-04-15] pooled Whole x1000: BS=70.8, JD=29.6, Heston=32.4\n",
      "[2025-04-16] pooled Whole x1000: BS=87.5, JD=35.7, Heston=48.0\n",
      "[2025-04-17] pooled Whole x1000: BS=51.3, JD=31.8, Heston=27.3\n",
      "[2025-04-18] pooled Whole x1000: BS=52.5, JD=32.8, Heston=28.1\n",
      "[2025-04-21] pooled Whole x1000: BS=104.8, JD=30.5, Heston=71.1\n",
      "[2025-04-22] pooled Whole x1000: BS=74.3, JD=48.1, Heston=41.4\n",
      "[2025-04-23] pooled Whole x1000: BS=62.9, JD=18.3, Heston=23.8\n",
      "[2025-04-24] pooled Whole x1000: BS=121.6, JD=46.4, Heston=98.1\n",
      "[2025-04-25] pooled Whole x1000: BS=134.0, JD=72.8, Heston=88.6\n",
      "[2025-04-28] pooled Whole x1000: BS=219.2, JD=156.9, Heston=167.9\n",
      "[2025-04-29] pooled Whole x1000: BS=127.2, JD=65.5, Heston=88.3\n",
      "[2025-04-30] pooled Whole x1000: BS=130.6, JD=66.0, Heston=91.6\n",
      "[2025-05-01] pooled Whole x1000: BS=139.4, JD=118.4, Heston=110.1\n",
      "[2025-05-02] pooled Whole x1000: BS=138.3, JD=68.2, Heston=95.6\n",
      "[2025-05-05] pooled Whole x1000: BS=160.3, JD=110.3, Heston=141.0\n",
      "[2025-05-06] pooled Whole x1000: BS=148.0, JD=73.4, Heston=99.7\n",
      "[2025-05-07] pooled Whole x1000: BS=154.4, JD=107.2, Heston=108.6\n",
      "[2025-05-08] pooled Whole x1000: BS=200.8, JD=173.1, Heston=143.9\n",
      "[2025-05-09] pooled Whole x1000: BS=144.2, JD=76.3, Heston=110.7\n",
      "[2025-05-12] pooled Whole x1000: BS=268.2, JD=251.5, Heston=202.4\n",
      "[2025-05-13] pooled Whole x1000: BS=175.5, JD=154.3, Heston=127.1\n",
      "[2025-05-14] pooled Whole x1000: BS=150.7, JD=145.6, Heston=96.5\n",
      "[2025-05-15] pooled Whole x1000: BS=152.0, JD=82.9, Heston=114.5\n",
      "[2025-05-16] pooled Whole x1000: BS=186.3, JD=122.0, Heston=118.3\n",
      "[2025-05-19] pooled Whole x1000: BS=216.6, JD=158.7, Heston=188.3\n",
      "[2025-05-20] pooled Whole x1000: BS=100.3, JD=31.3, Heston=89.4\n",
      "[2025-05-21] pooled Whole x1000: BS=207.8, JD=198.7, Heston=138.8\n",
      "[2025-05-22] pooled Whole x1000: BS=194.9, JD=188.4, Heston=208.1\n",
      "[2025-05-23] pooled Whole x1000: BS=179.0, JD=165.1, Heston=127.3\n",
      "[2025-05-26] pooled Whole x1000: BS=200.0, JD=189.0, Heston=156.2\n",
      "[2025-05-27] pooled Whole x1000: BS=192.8, JD=88.7, Heston=126.5\n",
      "[2025-05-28] pooled Whole x1000: BS=136.3, JD=91.7, Heston=90.8\n",
      "[2025-05-29] pooled Whole x1000: BS=138.0, JD=122.2, Heston=107.4\n",
      "[2025-05-30] pooled Whole x1000: BS=198.1, JD=147.5, Heston=124.2\n",
      "[2025-06-02] pooled Whole x1000: BS=190.8, JD=163.5, Heston=177.2\n",
      "[2025-06-03] pooled Whole x1000: BS=183.5, JD=139.2, Heston=117.6\n",
      "[2025-06-04] pooled Whole x1000: BS=184.2, JD=69.2, Heston=113.5\n",
      "[2025-06-05] pooled Whole x1000: BS=185.4, JD=139.6, Heston=146.7\n",
      "[2025-06-06] pooled Whole x1000: BS=214.8, JD=184.2, Heston=147.7\n",
      "[2025-06-09] pooled Whole x1000: BS=222.8, JD=91.4, Heston=176.9\n",
      "[2025-06-10] pooled Whole x1000: BS=156.9, JD=52.7, Heston=62.2\n",
      "[2025-06-11] pooled Whole x1000: BS=151.9, JD=47.2, Heston=66.8\n",
      "[2025-06-12] pooled Whole x1000: BS=168.1, JD=47.7, Heston=123.0\n",
      "[2025-06-13] pooled Whole x1000: BS=115.5, JD=94.9, Heston=82.6\n",
      "[2025-06-16] pooled Whole x1000: BS=149.1, JD=67.6, Heston=89.5\n",
      "[2025-06-17] pooled Whole x1000: BS=105.7, JD=99.7, Heston=69.5\n",
      "[2025-06-18] pooled Whole x1000: BS=141.2, JD=74.6, Heston=98.5\n",
      "[2025-06-19] pooled Whole x1000: BS=145.3, JD=76.8, Heston=101.6\n",
      "[2025-06-23] pooled Whole x1000: BS=159.5, JD=168.7, Heston=154.8\n",
      "[2025-06-24] pooled Whole x1000: BS=135.0, JD=135.1, Heston=96.8\n",
      "[2025-06-25] pooled Whole x1000: BS=172.5, JD=38.9, Heston=88.2\n",
      "[2025-06-26] pooled Whole x1000: BS=167.6, JD=150.3, Heston=109.9\n",
      "[2025-06-27] pooled Whole x1000: BS=172.3, JD=164.6, Heston=109.9\n",
      "[2025-06-30] pooled Whole x1000: BS=168.2, JD=140.9, Heston=105.1\n",
      "Saved: XOP_25Q2_baseline/table_ivrmse_equal.csv\n",
      "Saved: XOP_25Q2_baseline/table_ivrmse_equal.md\n",
      "Saved: XOP_25Q2_baseline/table_ivrmse_pooled.csv\n",
      "Saved: XOP_25Q2_baseline/table_ivrmse_pooled.md\n",
      "          Moneyness        Asset      BS      JD      SV\n",
      "0      Whole sample  XOP (τ=14d)  182.13  118.79  141.46\n",
      "1      Whole sample  XOP (τ=28d)  128.14   80.35   72.57\n",
      "2      Whole sample  XOP (τ=56d)   76.52   37.54   40.45\n",
      "3      Moneyness <1  XOP (τ=14d)  218.05  150.02  155.89\n",
      "4      Moneyness <1  XOP (τ=28d)  154.96   96.89   82.57\n",
      "5      Moneyness <1  XOP (τ=56d)   99.71   41.07   48.26\n",
      "6      Moneyness >1  XOP (τ=14d)  130.88   56.31  113.18\n",
      "7      Moneyness >1  XOP (τ=28d)   89.20   45.39   54.24\n",
      "8      Moneyness >1  XOP (τ=56d)   45.96   30.59   28.53\n",
      "9   Moneyness >1.03  XOP (τ=14d)  140.49   60.01  121.38\n",
      "10  Moneyness >1.03  XOP (τ=28d)   96.05   48.21   57.96\n",
      "11  Moneyness >1.03  XOP (τ=56d)   49.30   32.58   30.40\n",
      "          Moneyness        Asset      BS      JD      SV\n",
      "0      Whole sample  XOP (τ=14d)  202.48  152.63  163.50\n",
      "1      Whole sample  XOP (τ=28d)  143.14  106.56   84.36\n",
      "2      Whole sample  XOP (τ=56d)   86.32   49.05   49.96\n",
      "3      Moneyness <1  XOP (τ=14d)  240.36  198.50  182.96\n",
      "4      Moneyness <1  XOP (τ=28d)  172.30  137.38   97.75\n",
      "5      Moneyness <1  XOP (τ=56d)  113.48   58.96   64.75\n",
      "6      Moneyness >1  XOP (τ=14d)  154.61   78.57  142.73\n",
      "7      Moneyness >1  XOP (τ=28d)  104.10   58.62   67.14\n",
      "8      Moneyness >1  XOP (τ=56d)   51.96   38.82   34.21\n",
      "9   Moneyness >1.03  XOP (τ=14d)  165.60   83.36  152.74\n",
      "10  Moneyness >1.03  XOP (τ=28d)  112.46   63.15   72.42\n",
      "11  Moneyness >1.03  XOP (τ=56d)   55.79   41.41   36.51\n"
     ]
    }
   ],
   "source": [
    "res = summarize_symbol_period_ivrmse(\n",
    "    df_all=df,\n",
    "    symbol=\"XOP\",\n",
    "    start_date=\"2025-04-01\",\n",
    "    end_date=\"2025-06-30\",\n",
    "    buckets=[14,28,56],\n",
    "    min_parity_pairs=4,\n",
    "    tau_floor_days=3,\n",
    "    run_bs=True, run_jd=True, run_heston=True,\n",
    "    show_progress=True,\n",
    "    print_daily=True,\n",
    "    out_dir=\"XOP_25Q2_baseline\"      # outputs saved here\n",
    ")\n",
    "\n",
    "# PRIMARY (paper): equal-day mean table\n",
    "tbl_equal = make_publication_table(res, symbol=\"XOP\",\n",
    "                                   measure=\"equal\",\n",
    "                                   buckets=[14,28,56],\n",
    "                                   decimals=2,\n",
    "                                   out_dir=\"XOP_25Q2_baseline\",\n",
    "                                   basename=\"table_ivrmse\")\n",
    "\n",
    "# SECONDARY (robustness): pooled table\n",
    "tbl_pooled = make_publication_table(res, symbol=\"XOP\",\n",
    "                                    measure=\"pooled\",\n",
    "                                    buckets=[14,28,56],\n",
    "                                    decimals=2,\n",
    "                                    out_dir=\"XOP_25Q2_baseline\",\n",
    "                                    basename=\"table_ivrmse\")\n",
    "\n",
    "print(tbl_equal)\n",
    "print(tbl_pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba42c19-5c34-4f2c-a18e-4abdea5a5f56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
